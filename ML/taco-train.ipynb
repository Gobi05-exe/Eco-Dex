{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7bce0f7",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T04:16:52.026538Z",
     "iopub.status.busy": "2025-06-25T04:16:52.026266Z",
     "iopub.status.idle": "2025-06-25T04:17:27.178936Z",
     "shell.execute_reply": "2025-06-25T04:17:27.178189Z"
    },
    "papermill": {
     "duration": 35.163018,
     "end_time": "2025-06-25T04:17:27.186248",
     "exception": false,
     "start_time": "2025-06-25T04:16:52.023230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/TACO_with_hard_negatives/data.yaml',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000061_jpg.rf.7779d6ce157b1c650648a2e9de0b5d38_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4876_JPG.rf.e01212e9b631ca54cda9a0fc935ddc9c_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/9000020_jpg.rf.a311c90f84f41a91a12535ba484663de_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000127_JPG.rf.da5be93c943766123144a46a38675088_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000498.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/reusable-cup-with-paper-straw-womans-handzero-waste-lifestyle_377884-382_jpg.rf.e2a66ede5b35617e5f74c710f69617a5_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000189.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000034_JPG.rf.cb1f16a29cffe1e2258db8dc0a62355f.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_5048_JPG.rf.d835e83680cf78b7b3986cefbb8f9d6a.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/rty0srprsti31_jpg.rf.1dc31ee077d52b962a02007676f5a740_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000025_jpg.rf.72fe9551738c7dbb002e7132989dba30.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/100_jpg.rf.044e1fe79151baf0671a8166ea40a258.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000049.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000086_JPG.rf.34ab1155e8b52024f953da76472976a9.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000135.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000071_JPG.rf.a6a91aa069cb8516c2a8348817a851a0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000431.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000088.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000081_JPG.rf.a94d6107cb6c6aa81c824880a6e8d8c9_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000352.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000045_JPG.rf.3bc5864ca9ff079e67cbf23db396f567.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000023_JPG.rf.0d43c9978b915812fb1888496f68cd75.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/23-2-_jpg.rf.fd92b012e55e5358518768bb29881013.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000038_JPG.rf.61297654510b0d512d9c8518ef439f8b.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/8000071_jpg.rf.19a3f8e03530ab453da600affc47a0cc_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000017_JPG.rf.720e47fb2c3d8be3994dbb41d49c0cbb.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000415.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000059_jpg.rf.edbe31d00d09c0eaae77509144d7ac22_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000063_jpg.rf.206563f196b6b448456b6e22f6e4683c.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000059_jpg.rf.7be926b5970dca079e98c31e8ad4101e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000094_jpg.rf.bf70acc9d6ad236c23f0f9bd6b779ab1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000018_jpg.rf.ef24fa9f9d4ab1116c40da3b8753a452_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12_jpg.rf.9e64d4ec9ef22acbb51eeccc0f876bcd.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000370.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000055_jpg.rf.ec7015b4cd7ffafbed3b37a817430746_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000183.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000059_jpg.rf.8dc4e3978437e18a0cf6edc77a3dc967_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000027.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000088_JPG.rf.c8c5e691bf757236393ef0db1d15bb10_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000386.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000455.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000013.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000316.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000115_JPG.rf.ef8d9ebe8ba72fce3f5bc4d612a77c00.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000127.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4876_JPG.rf.e01212e9b631ca54cda9a0fc935ddc9c_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/47_jpg.rf.90d50076ca18fea263af298ab02f4134.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000091_jpg.rf.53a9d02074f73b853be284fedaef1658.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000050_JPG.rf.344d00bccede12dc56716613538ba70a_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000006_jpg.rf.a3c08bd607ddebcce77e5a7e4afeff63.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000028_jpg.rf.065f43fc5efba5fe9518c16a25454056.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000001_jpg.rf.2d1d15d623fde54b94304acca1281f7c_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000502.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000018_JPG_jpg.rf.c733493a70145a9e195f706d9bdd183a.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000061_jpg.rf.aa7735c75eb684b5d9540ecd75483bd0_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000028.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000066_jpg.rf.9eedc94d97f999a6dedd283deddbe68c_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000010_jpg.rf.cce68f7dce2285fc52fc8ba68e543f9e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/9000008_jpg.rf.ba86f14fae31cf9b8b62be6286ccedc5_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_5055_JPG.rf.d8615193cab3a93f1bf8e0df5cbf8fe1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000022_JPG.rf.1d48e2ecaa1421655bf7d5e945d320b4_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000422.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000056_jpg.rf.f750e73567c91610a716af78ed696dc0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/8000086_jpg.rf.927b8d9c4194f371bcfdaf030ea3729f.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4876_JPG.rf.e01212e9b631ca54cda9a0fc935ddc9c_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4928_JPG.rf.2cff2e3a2231122bb1abeca2882783f0_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000182.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000010_jpg.rf.97bbb3b9389f6a2cf189d606ada8d25e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000055_jpg.rf.b62e02171adf9d5b9eba87cb7af9aadb_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000072_jpg.rf.421628ba41367ff434adaca26ee9655f_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000100.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000111_JPG.rf.ab4ed3daddc53a21017eec71afcdb15d_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000054_jpg.rf.82a56ae9ec544ace7f0b194f72419bc6_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000029_jpg.rf.3c553a5f9f91ced137be5ee2ef8334bf_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000009_JPG_jpg.rf.acd5828a16ac889fa4cef266de574c04_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000110.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000034.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000070_JPG.rf.6886a154f89e447537b29588577e3cd6.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/8000012_jpg.rf.740e360d26845133afe564aabc95abf9.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000225.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000068_JPG.rf.473d1340c06afb71f5d8e4d6f5de66b3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000015_JPG.rf.46fc5def1434c1dd8c66ec11f8b492a7.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_5066_JPG.rf.1cc9c8ab829529980a09b67182e5e81f.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000074_jpg.rf.bc9a092ce6e0e86ab38819e6c3c306b6.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000117_JPG.rf.7d531d83f1f3a909b367607b2322dd72.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000480.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000092_JPG.rf.a8f975830abd7a108859f347f25598f9_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000081_jpg.rf.46349092b46cadc11e61dd63b1ff0e9a.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000059_jpg.rf.7194db66729443583bba7c5b2ece1bf3_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000056_JPG.rf.b40b1aaca1a14e673ee16a218bb84201_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/20_jpg.rf.460d83b48fab5cfd375c55c8ce5bfa2b.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000024_jpg.rf.79e93483a1135261df4e992784b0c66e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000201.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000037_JPG_jpg.rf.47dc28275fbc694b110913ce5d094cb2_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4878_JPG.rf.bb8bce15203145cec24968ae64d25bea.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000080_jpg.rf.2137fdfeacd35233b1a191702dbf21a1_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000078_JPG.rf.15624980ab5b38e5589e767b29df2bf4_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000037_JPG_jpg.rf.e0c46c45372dde87645f1c001576092b_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000033_jpg.rf.3f358224c36f164b8b3e0843a68803ef.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/29-3-_jpg.rf.0704fac61273896c371faea446e6f4b7_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000369.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000057_jpg.rf.1412c6b9f95aa25fb49d691250a9b8ca.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000215.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000078_JPG_jpg.rf.3804147a0c76a30b5dca8092c6024b18_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000374.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000398.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/9000050_jpg.rf.2f894e078f87f126a8306fe87afe4cd4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_5036_JPG.rf.a0a6a21907ee01b6d454cb598db1a1d7.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000084_jpg.rf.ff041efbbe7dd656e362eeaeaf1a070f.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000136_JPG.rf.afc19831d68c25ea5286a605366857e3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/29-4-_jpg.rf.dda5718f35135ec065d16858a5de9af2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/23_jpg.rf.741640ffea69ec6307b302b96b6fe3d2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/108-4-_jpg.rf.593f6ef5c8aaa96e4c1ca6e4477da8b2_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/nppoi4iy6ue11_jpg.rf.cdb73b5f4f44f5990b65de4ee433833d_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000338.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000069_JPG.rf.cf5796ce70a3e051b6c95dc82fe30c13.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000028_jpg.rf.065f43fc5efba5fe9518c16a25454056_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000039_jpg.rf.dfa52be5a37e5e97be23845da7e588bb_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/28_jpg.rf.4858b7dc0636e220e1e20a8f4db2023e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000098_jpg.rf.e5a1665097cdfdc1215d053cf0e50d41.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000028_jpg.rf.9c0c0409e1d85fd59b974d52905eafea.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000065_jpg.rf.f971cb875068e23635c6912eb0476222_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000041_JPG.rf.6a4413de3426e994050bed89e32becd2_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/8000002_jpg.rf.0ada82d41a5152d1a79b77cbef945c76.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/28-2-_jpg.rf.068adfe53d4a297ea6e6062bfd28f106_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/2000005_JPG.rf.b5f86425dc46715b1bcb554f450d499e_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000053_jpg.rf.447449e6b981ea94591317b6533cefde_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000041_JPG.rf.6a4413de3426e994050bed89e32becd2_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000047_jpg.rf.722346785de0e6af2fe693f0a9e7c7a2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/14000025_jpg.rf.4ad092cd0782605c0f707e64c07c7be1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000055_JPG.rf.2001eba4f681bd196d980868a189e4c4_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000108_JPG.rf.10871f11f9f7f225499892ebc8986db7.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000051_jpg.rf.f8ac9557e1b928b6f6cd85616972022c_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/8000099_jpg.rf.f73af5bd219bce6b43ff29790b0ca656_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000096_jpg.rf.7c6bedd3708771efbb6ae085f6286f13_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000366.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000019_jpg.rf.f1e03643697d13984eae6c537b3b51d3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000126.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000008.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/19-2-_jpg.rf.cfb45fb5ec28a43afe27ab34a8eaf6f8.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000069_JPG.rf.587795def37936651dc29a692e978e05.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000260.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000003_jpg.rf.4fee21529a27b262670330b7f4aee02c_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000322.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000015_jpg.rf.86d6b3e9a1c78d9c62630c52238026d7_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000003_JPG.rf.b1577e3766e8944e57228a5e1a9cf2db_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_5066_JPG.rf.1cc9c8ab829529980a09b67182e5e81f_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000314.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000031.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000492.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/2000088_JPG.rf.9aa79030d9992c3cc83d738379d1ad72.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/9000077_jpg.rf.324178077dc2b32de5a197f1602c2817.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000069_jpg.rf.30cad46efae7e4e32ace995b5add97e0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000482.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000210.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000180.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/14000032_jpg.rf.9503bdc48620fcb0a73abc292146baff.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000097_jpg.rf.65d4f8e09fb5305d78bdd31cd0feaa30.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000076_jpg.rf.9d4895e46bf508dd23dd7b67643876cc.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000091_JPG.rf.30b2b7214dbb033f53a6a7c38adbc58a.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000076_jpg.rf.a6f028f70879b585d45d14c726af7b46.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000041_JPG.rf.2ab232e7ec3703b80a3508e33dc21c07_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000061_jpg.rf.7779d6ce157b1c650648a2e9de0b5d38_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000444.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000070_JPG.rf.6158d08cb473eb5c49ecb928e1fd0a8e_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/IMG_5050_JPG_jpg.rf.f2a59223d3e70ae3ac894a2f23427851_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000095_jpg.rf.0666392a6badca35a930c63622eaf31e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000161.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000007_jpg.rf.4433baf9c84ed7c7f756b41ca2b22f2e_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/IMG_4922_JPG_jpg.rf.ca3a95d60e818cd5f5f9fa1ab6c7b6e3_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000136.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000090_jpg.rf.ea06ffd03250a44cb11ed647ff6c211c.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000167.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000047_JPG.rf.98fc987a35f5456330a543e057989a38.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/mcdonalds-empty-cola-cup-with-paper-straw-mcdonalds-is-the-worlds-largest-chain-of-hamburger-fast-food-restaurants-W9YFGJ-transformed_jpg.rf.03d9d09d620bee82a84ee3460c1a48b2_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000016_jpg.rf.78be6070e19acb6d4206b07c49cfe1e4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000049_JPG.rf.6b83b56d8282790c24afcfc58eebc6a6.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000175.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000110_JPG.rf.58f085b607a5433a0a0a64bc3f54750a.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000039_JPG.rf.6ac5cb5a978b26e48900719386f67c22.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/14000055_jpg.rf.a1a77e7bacca4b637344bb3d17b213fc_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000022_JPG.rf.08cb5dde75973a926816bbe647ca9e3e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000001_jpg.rf.2d1d15d623fde54b94304acca1281f7c_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000008_JPG.rf.294af3c767d7d6f89832ef53cfc18b87_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000009_jpg.rf.15439969346f126ed9ecc2ca1a36d5fb_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000050_jpg.rf.168150975d082cb65e00e8dde1d85fb9.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000013_jpg.rf.64be493563d6a920a324f7d1491bf24c.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000028_jpg.rf.48cb79b8121d748a527fbf0dd2678d86.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000009_JPG_jpg.rf.acd5828a16ac889fa4cef266de574c04_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000055_jpg.rf.f147e26a6457d42c0ea7b2552ace4a88_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000077_JPG.rf.07c472e7a163f86c17d3ff483ade0a89.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000099_jpg.rf.716f55cd467e5c0739d20b395fcbdc07.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000027_jpg.rf.ee802b53c28178f993a474a69668c2a2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000112_JPG.rf.1603714aa26a5869a9c90d14fc0e9455.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000124.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/9000056_jpg.rf.65af827318858296ff7f12276f7c0b64.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000139.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000071_JPG.rf.445727a1d46d57ec83b57b07626b6380_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000050.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/8000052_jpg.rf.e6e9ed469e389c67ad5cdaac6fdb5da1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/14000019_jpg.rf.1e3d9654c36894011965b49004d46583.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000071_jpg.rf.a48161090011ed8cb2497954b1ea812a_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000061_jpg.rf.b38207cd4aa539d8446fc7a1339dcf08_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/IMG_4922_JPG_jpg.rf.ca3a95d60e818cd5f5f9fa1ab6c7b6e3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4868_JPG.rf.3e42948997f641da25ab729ba71d5f36.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000054_jpg.rf.9d2760ae155e81b1ba87eea5a032dd5e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000027_jpg.rf.13b71c45f89f3952dea13ff000d1e436_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000040_JPG.rf.8ce95d8a1970a9bbb83477a41cb05517.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000005_JPG.rf.24425e9dbfb6c79b42b1de78ac57c324_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/26-3-_jpg.rf.c41ef082e1b327ca098e26e54ccec9ae.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000058_jpg.rf.72e21cc4377fc37797f7d18ef039d52e_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000516.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/IMG_4922_JPG_jpg.rf.ca3a95d60e818cd5f5f9fa1ab6c7b6e3_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/119-3-_jpg.rf.ead46c6b3877cbdb22e30592d4ad9845.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000037_JPG.rf.8b7f7fd3c17eb52065551914a09141f2_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/IMG_5050_JPG_jpg.rf.f2a59223d3e70ae3ac894a2f23427851_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/e3l2833k0lx21_jpg.rf.41fd25013e84f39a9bd6f268e52e19c8_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000075_JPG.rf.b52b0b995d8209ce827fd15293765a16.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000056_jpg.rf.6ee5dc3aab1c0ba032abd3d08e6b8e9d.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000105_JPG.rf.a0210840727d8b6ed1e715734261f60b.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/9000075_jpg.rf.c258246eb401d7a964c36ecafea92f7e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000004_jpg.rf.968f2e164950eb66cede497ae72a17da.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000021_JPG.rf.89d63a8d463a4820c1247bbe3013ed48.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000121_JPG.rf.950f0a654b9de44a80cca689844be087.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000214.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000045.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000056_JPG.rf.b40b1aaca1a14e673ee16a218bb84201.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000015_jpg.rf.230ad17a0d923f083e7ce6aa50ae1d24_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_5003_JPG.rf.d31943153a40c0ff3dd4d236116ffef5_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000029_jpg.rf.e04d5945eb1439aaf062974756da20cd.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000111_JPG.rf.ab4ed3daddc53a21017eec71afcdb15d_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000056_JPG.rf.93f4f41f72578b33042017da495768ed_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000018_jpg.rf.3c7c2e5f5fdf36ca3fcc0c2420673e32_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/8000066_jpg.rf.b83d6ba59c9db0fdbbbf255e790ade56.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000102_JPG.rf.a01070aa3e46790848a18339d8f29721_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000037.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000065_jpg.rf.48e670b619ce9b09f2f21f298cdca522.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/DnILtx1WsAAHAoc_jpg.rf.2d5cf8a645aac8ebbec09513e9847d9a_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/14000074_jpg.rf.ba02cc7abb61e2d9634b9473ae3bd2d8.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/2000097_JPG.rf.e8dbc8d4baf14ce734c88477964f408e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000114_JPG.rf.fc346afb1b7870e68486435e76c7b8f2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000015_jpg.rf.230ad17a0d923f083e7ce6aa50ae1d24_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000104_JPG.rf.5c4306f6e470d788c87d99d2838ff2f2_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000057_JPG.rf.bd9dc1bbef5995c1474f73abd7310419_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000032_JPG.rf.d78550e741d045dcfae2e4944d998c00.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000098_JPG.rf.e9f5a589a2622da69447df25b36b9903_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000056_jpg.rf.3160ea007c8b7f002e03da0d91cda916.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000403.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000071.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4897_JPG.rf.70a68cd13aa4679f5fc1ec0d142b2ae4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/8000082_jpg.rf.d5cc6604696df93153f8178bea422f56_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000280.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000111_JPG.rf.f094396c7be3431dddcdf37b5d5c04e4_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000018_jpg.rf.e17daa7a548c2fa23e6ffcad54aba23b.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/14000034_jpg.rf.fdbf0371d72220bb9683cde8df529c09.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000464.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/14000009_jpg.rf.f2280bbdfdec19a51cb27517e8ad8ec4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000061_jpg.rf.aa7735c75eb684b5d9540ecd75483bd0_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000020_jpg.rf.6f9684fcd8098171f6f58a8b15ca28b1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/2000042_JPG.rf.01e882a16980029dcaa76056b51ecd24.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000089_JPG.rf.ca847c016129f0684ac0912d0bc323c0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000089_JPG.rf.de3bb7635da2f26b751ed943508a7be0_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000226.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/101-3-_jpg.rf.54849d0c76489288e6b790ae1764e379.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000456.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000011_jpg.rf.02a1f97705abe7afaaff65a3ce9c74c8.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000011_jpg.rf.95186b47c50ed41f564fafb77f132b9c.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000015.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_5039_JPG.rf.0c3f9e2b784f08ff32a3d0b54ec92ecf.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/101-4-_jpg.rf.28c30960e1fee6abff609343f5e559fd.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000015_jpg.rf.44c9a8f99794464d3a9f8aa6c3fc06a5.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000141.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000282.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000085_JPG.rf.fa571584a44399d0456f39becdb5b230_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000049_JPG.rf.4d48022d1b984d5bfe73a43b33638505.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000152.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000070_jpg.rf.03477027b2e3d800b0b3bd734c049f32_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000156.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/9000040_jpg.rf.334a8485d164a35f0831318054f272bc.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000019_JPG.rf.1a02e8cffe0b3b98231f7e33ffee8418.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000061_jpg.rf.8cfc8875fec0b216f186929de7a48dab_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000472.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/9000010_jpg.rf.e021e326de8489308443c3755579c2fd.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000495.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000009_JPG_jpg.rf.70bfad3af9af85f59f72d94c642a1ad4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000016_jpg.rf.389acf3f45d617b4d5b9e5d409f54a83_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000027_jpg.rf.b9478e6e21138748512f0d3bc92f98bf_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000006.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/30_jpg.rf.c5f1719e709bc655e252e21821a53520.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000022_JPG.rf.1d48e2ecaa1421655bf7d5e945d320b4_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000018_jpg.rf.3c7c2e5f5fdf36ca3fcc0c2420673e32_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000054_jpg.rf.a1c79e3d36f4f3e6c6a5ff16c2db21a1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000184.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000019_jpg.rf.4d068af7c9fc06933fa7d8ddfe5e5587_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000007_jpg.rf.5c8d44e7a6132214745aa57e1ca48e1c.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000039_JPG.rf.46c9ef448b79d140a5f1c093550ff9f9.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000060.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000073.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000085_jpg.rf.5a23c6e362f38b067b62f6c2e77b7bed.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000102_JPG_jpg.rf.9db5692910c4398495ce8d943b4c261c_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000037_JPG_jpg.rf.155fc753cb0020965a3b7004500d747e_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000039_jpg.rf.d8488b95e25bf63dd66548d11b2596b6.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000066_JPG.rf.0aaa612ae531db8eecd39a5c3468761b.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000423.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000060_jpg.rf.f36febe9e287109171ec78c579d7d1b1_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/14000097_jpg.rf.a7edb7be309ad362508449f929c2c6eb.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000037_JPG.rf.e5aef7caa30ed733e8d111fdd734d02f_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000236.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000011_jpg.rf.95186b47c50ed41f564fafb77f132b9c_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000035_JPG.rf.64b9297f72298955ff3c1892e698bee6_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000097_JPG.rf.f657bcec135c21adaed2d52a0da85481.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4967_JPG.rf.23522de144c2e441df07b1d7c257caa5.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000022_JPG.rf.1d48e2ecaa1421655bf7d5e945d320b4_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000051_jpg.rf.39b8c63b715469f22063d57bc8195353.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000095_JPG.rf.0b1a2c9eb12e68fc821b8a372948b623.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000054_jpg.rf.640c6c7410864ead814fcb6f0fc348cc.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000018_JPG_jpg.rf.c733493a70145a9e195f706d9bdd183a_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/14000004_jpg.rf.a6aa126827e7881b212907cbfc7caf1f.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000507.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000271.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/8000082_jpg.rf.d5cc6604696df93153f8178bea422f56_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000097_JPG.rf.7cb6ae27d2c0b355f16d7da7a31851e6_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000111_JPG.rf.ab4ed3daddc53a21017eec71afcdb15d_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4916_JPG.rf.403fd7e12fb74e30ca7d99dc69da5602_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000063_JPG.rf.6b495e60eb5197b98ce7434cec70f7d1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/9000036_jpg.rf.34118f8cc941b38f50cb1cdb261fc583.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000092_JPG.rf.a8f975830abd7a108859f347f25598f9_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000059_jpg.rf.125f60cd509f1aaa148e2e543bd35488_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/8000001_jpg.rf.03d193c95fb05ea13bf9d811a0eafc93_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000017_JPG.rf.720e47fb2c3d8be3994dbb41d49c0cbb_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4898_JPG.rf.f59b8a7c73ccf25920e726ae7fb09125.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000416.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000055_jpg.rf.bb7501cb6e605317e1b70a3cbfec0780.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000153.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000015_JPG.rf.90141e64c830e9c2ccd1fc0286acb67c_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4862_JPG.rf.6ffb2eef830618f992cd215e29051485_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000344.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000477.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000124_JPG.rf.9f616b2f82b3b60688ed109c15d455b3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/117-2-_jpg.rf.2739d91e982188929fb8f4a64540d54b.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000097_jpg.rf.fc5c4d7b9dba1b8690dd9a3647cbab87.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000069.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000095.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000050_jpg.rf.11ea2c51928d3b8af94b14800306fb95.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000020_JPG.rf.0dbe9ad2507345d5be88732504f00365.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000056_jpg.rf.ff4b1d904d1af63884ebcd891176a2ff.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000076_jpg.rf.b8791ed7a41fd35d1282ab5a0f6e0da7.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/2000068_JPG.rf.0887a6cdf545cd6e129a0c2566bacc5d_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000224.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000014_JPG.rf.3e32cd388ee343d7c65f3f656c8dc065.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000011_jpg.rf.95186b47c50ed41f564fafb77f132b9c_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/9000000_jpg.rf.c316cb11c5d4f7c878290ba37c799842_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000026_jpg.rf.8d1573707aa5900c1e9f59570e83464e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000061_JPG.rf.e8212d988d62eb47039add0bde1388c4_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000080_jpg.rf.2137fdfeacd35233b1a191702dbf21a1_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000045_jpg.rf.c30e010025292830406e6770fd9b5170.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000098_JPG.rf.5c7fc087c134b0f8ea0900776661581b.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000104.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000111.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/2000010_JPG.rf.024854d3e6262db77092cea1471cd9e9_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000281.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000256.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000090_JPG.rf.58dd7ca253a90136c01016aaa3bb8b1f.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000084_jpg.rf.8e9131f2072ac71c09c8407bf8afb9db_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000056.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000106.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000069_JPG.rf.a0cef55bfb88ce202ec2f200151f5d84.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000078_JPG_jpg.rf.5b401c9371f5a53e15a2a7f3a2d3d917.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000108_JPG.rf.10871f11f9f7f225499892ebc8986db7_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000079_JPG.rf.2b2a909b175dd5fea731467dee60a881.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000359.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000099.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000086_jpg.rf.aa66ff6f46320a0143f3f6a122c0e860.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000442.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000232.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000032_jpg.rf.af0e698ceceef5c9d0242474748b515e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000011_JPG.rf.753279452a4c7983b4dfeb0c4dd258b6.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/11000059_jpg.rf.7194db66729443583bba7c5b2ece1bf3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/throwing-crumpled-paper-paper-glass-paper-straw-and-plastic-bag-into-the-trash-can-in-home-or-office-free-video_jpg.rf.e8c857d491e207f8b881971ed33ebf4b_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000057_jpg.rf.7233082ac866d1e1c72ab096a3a0865a.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000118_JPG.rf.a32ae4b525c0b9c333248eaa6302a931.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000108_JPG.rf.10871f11f9f7f225499892ebc8986db7_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000008_jpg.rf.f97e08741f4c896fc0a388f63619cd06.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4965_JPG.rf.910c71eee92b8c1c2c61bc9b546208b6_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000490.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000107_JPG.rf.94665032a88c2e76901580f5e95d6a76_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/29-3-_jpg.rf.0704fac61273896c371faea446e6f4b7_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000118.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000367.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000096_JPG.rf.dc385dbf252d9c55d64db1c8a6353d1a_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/9000005_jpg.rf.7450470e1734364d6604ffa7ebc19ca8.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000009_JPG_jpg.rf.70bfad3af9af85f59f72d94c642a1ad4_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000057_JPG.rf.bd9dc1bbef5995c1474f73abd7310419_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000102_JPG.rf.a01070aa3e46790848a18339d8f29721_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000171.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/35-2-_jpg.rf.19a060d6644f8dfe654b7c41f9a9dcfe_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000088_JPG.rf.c8c5e691bf757236393ef0db1d15bb10_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000005_JPG.rf.24425e9dbfb6c79b42b1de78ac57c324_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000258.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000059_jpg.rf.0d88e63ee80308de7f58723803220c1f_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_5049_JPG.rf.91676f3d05686f10bc0c2d32cbe45c96.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000029_jpg.rf.3c553a5f9f91ced137be5ee2ef8334bf_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000050_JPG.rf.344d00bccede12dc56716613538ba70a.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000030.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000430.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000048_JPG.rf.bd02b51986eaa411278fc59290ebb0d2_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000061_JPG.rf.e8212d988d62eb47039add0bde1388c4_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000015_jpg.rf.86d6b3e9a1c78d9c62630c52238026d7_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4948_JPG.rf.4cec287ba4a361e2f918492cdd190f32_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000051_jpg.rf.f8ac9557e1b928b6f6cd85616972022c_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/116_jpg.rf.0cbe58c41c7586920c30dbcb0fbef7ac.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000037_JPG_jpg.rf.4975f92be54596d95aa88c48833eafc6_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000054_jpg.rf.2f23611817ac6aca44a74fe3e1483aeb_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000028_jpg.rf.5654a6ca23a5106493bc198fa6b7b3af.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000019_jpg.rf.fd09135bbde59bd3d6f935711b799d8e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/14000052_jpg.rf.d93d0ed7d06e13529e2fb1c20f90d917.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/12000048_jpg.rf.4d871babec1a2bdf083d46ddaf60336c.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/4000041_JPG.rf.6a4413de3426e994050bed89e32becd2_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/29-3-_jpg.rf.0704fac61273896c371faea446e6f4b7_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000039_JPG.rf.e9e8f6c22a7910d1b4d8e78acbd648c9_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/105-2-_jpg.rf.7564e7f50fdbca90e891c94aeb7511e5.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000035_JPG.rf.64b9297f72298955ff3c1892e698bee6_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000025_jpg.rf.b607018861077e04d4b487baafecaa7a.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000296.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000335.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000077.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000055.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000302.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000107_JPG.rf.94665032a88c2e76901580f5e95d6a76.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4919_JPG.rf.d34e9331a71867c724efff300ed11c16.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000410.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/2000075_JPG.rf.172818874d5abd69d3a547733c92df08.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000071_JPG.rf.091bbf1400906bf890940432e1c7e304.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/8000021_jpg.rf.6374af5ebaad86af472e9a2ebcd7d72e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000254.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000350.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000026_jpg.rf.543648fb34b24e3662e7d48f8e352d79_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000046.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_4879_JPG.rf.ead0c40b9b5e5471191657e1a0124da7_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000022_JPG_jpg.rf.3c6f29a466b040fce166b513993bc512.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_5068_JPG.rf.d951fa97e60626c79227d1414cf3d67d.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/118-4-_jpg.rf.78c81bfc84364d849c967eead4745d83.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/15000046_jpg.rf.f95b2edb26e8d60a1657b3a8a5275ee7.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/3IMG_5063_JPG.rf.a96b7be1746b01613ff5c164eea581b3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000137_JPG.rf.7f8f9d9a972843b74bd3d9e63bcbd6cb.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/6000065_JPG.rf.130ccac8f92e8f745d2fca0b279af195_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000295.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/000037_JPG_jpg.rf.8d61d4383778937ef5eb0729adef9d06.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000240.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/1000095_JPG.rf.37fce843784c572511c0c91a407260e9_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/10000017_jpg.rf.a600e50317e4c084b833bf1f8d6f77d1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/5000075_JPG.rf.371cff3fb0d59890fd957dfba3f3e898_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/13000080_jpg.rf.16562dc1ba7744c2beb6a13ea486eefb_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/7000065_JPG.rf.2f66e2e4d33d9697346b65e9971181e2_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000187.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/labels/Places365_val_00000206.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000124.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/2000097_JPG.rf.e8dbc8d4baf14ce734c88477964f408e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000049.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000053_jpg.rf.447449e6b981ea94591317b6533cefde_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000136.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000031.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/9000005_jpg.rf.7450470e1734364d6604ffa7ebc19ca8.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000018_JPG_jpg.rf.c733493a70145a9e195f706d9bdd183a.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000296.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/116_jpg.rf.0cbe58c41c7586920c30dbcb0fbef7ac.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000111_JPG.rf.ab4ed3daddc53a21017eec71afcdb15d_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000444.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000013_jpg.rf.64be493563d6a920a324f7d1491bf24c.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000187.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000225.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4876_JPG.rf.e01212e9b631ca54cda9a0fc935ddc9c_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000104.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000065_JPG.rf.2f66e2e4d33d9697346b65e9971181e2_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000455.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000066_jpg.rf.9eedc94d97f999a6dedd283deddbe68c_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000011_jpg.rf.95186b47c50ed41f564fafb77f132b9c_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000028.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4916_JPG.rf.403fd7e12fb74e30ca7d99dc69da5602_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/14000019_jpg.rf.1e3d9654c36894011965b49004d46583.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_5036_JPG.rf.a0a6a21907ee01b6d454cb598db1a1d7.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4897_JPG.rf.70a68cd13aa4679f5fc1ec0d142b2ae4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/14000097_jpg.rf.a7edb7be309ad362508449f929c2c6eb.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000089_JPG.rf.ca847c016129f0684ac0912d0bc323c0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000069_JPG.rf.587795def37936651dc29a692e978e05.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000037_JPG_jpg.rf.4975f92be54596d95aa88c48833eafc6_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000482.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/9000000_jpg.rf.c316cb11c5d4f7c878290ba37c799842_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/23-2-_jpg.rf.fd92b012e55e5358518768bb29881013.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000032_JPG.rf.d78550e741d045dcfae2e4944d998c00.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000015_jpg.rf.230ad17a0d923f083e7ce6aa50ae1d24_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/9000075_jpg.rf.c258246eb401d7a964c36ecafea92f7e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000071_jpg.rf.a48161090011ed8cb2497954b1ea812a_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000001_jpg.rf.2d1d15d623fde54b94304acca1281f7c_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000048_JPG.rf.bd02b51986eaa411278fc59290ebb0d2_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000171.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/9000036_jpg.rf.34118f8cc941b38f50cb1cdb261fc583.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4928_JPG.rf.2cff2e3a2231122bb1abeca2882783f0_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000403.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000038_JPG.rf.61297654510b0d512d9c8518ef439f8b.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/8000021_jpg.rf.6374af5ebaad86af472e9a2ebcd7d72e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000135.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000017_JPG.rf.720e47fb2c3d8be3994dbb41d49c0cbb.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000089_JPG.rf.de3bb7635da2f26b751ed943508a7be0_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/8000052_jpg.rf.e6e9ed469e389c67ad5cdaac6fdb5da1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/2000005_JPG.rf.b5f86425dc46715b1bcb554f450d499e_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000104_JPG.rf.5c4306f6e470d788c87d99d2838ff2f2_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000028_jpg.rf.48cb79b8121d748a527fbf0dd2678d86.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/100_jpg.rf.044e1fe79151baf0671a8166ea40a258.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4878_JPG.rf.bb8bce15203145cec24968ae64d25bea.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000086_jpg.rf.aa66ff6f46320a0143f3f6a122c0e860.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/29-4-_jpg.rf.dda5718f35135ec065d16858a5de9af2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/8000001_jpg.rf.03d193c95fb05ea13bf9d811a0eafc93_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/105-2-_jpg.rf.7564e7f50fdbca90e891c94aeb7511e5.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/26-3-_jpg.rf.c41ef082e1b327ca098e26e54ccec9ae.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/8000012_jpg.rf.740e360d26845133afe564aabc95abf9.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000078_JPG.rf.15624980ab5b38e5589e767b29df2bf4_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000065_JPG.rf.130ccac8f92e8f745d2fca0b279af195_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000214.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000415.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000095.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000182.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000057_JPG.rf.bd9dc1bbef5995c1474f73abd7310419_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_5055_JPG.rf.d8615193cab3a93f1bf8e0df5cbf8fe1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000009_JPG_jpg.rf.acd5828a16ac889fa4cef266de574c04_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/23_jpg.rf.741640ffea69ec6307b302b96b6fe3d2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/2000010_JPG.rf.024854d3e6262db77092cea1471cd9e9_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000095_JPG.rf.0b1a2c9eb12e68fc821b8a372948b623.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000088_JPG.rf.c8c5e691bf757236393ef0db1d15bb10_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000056_jpg.rf.ff4b1d904d1af63884ebcd891176a2ff.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000028_jpg.rf.9c0c0409e1d85fd59b974d52905eafea.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/29-3-_jpg.rf.0704fac61273896c371faea446e6f4b7_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000092_JPG.rf.a8f975830abd7a108859f347f25598f9_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000059_jpg.rf.edbe31d00d09c0eaae77509144d7ac22_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000215.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000442.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000019_jpg.rf.f1e03643697d13984eae6c537b3b51d3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000050_jpg.rf.168150975d082cb65e00e8dde1d85fb9.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4967_JPG.rf.23522de144c2e441df07b1d7c257caa5.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000080_jpg.rf.2137fdfeacd35233b1a191702dbf21a1_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/29-3-_jpg.rf.0704fac61273896c371faea446e6f4b7_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000054_jpg.rf.640c6c7410864ead814fcb6f0fc348cc.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000037.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000055.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000111_JPG.rf.ab4ed3daddc53a21017eec71afcdb15d_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000338.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000100.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000026_jpg.rf.543648fb34b24e3662e7d48f8e352d79_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000045_jpg.rf.c30e010025292830406e6770fd9b5170.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000084_jpg.rf.ff041efbbe7dd656e362eeaeaf1a070f.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000037_JPG_jpg.rf.e0c46c45372dde87645f1c001576092b_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000110.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/14000004_jpg.rf.a6aa126827e7881b212907cbfc7caf1f.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000027.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/2000075_JPG.rf.172818874d5abd69d3a547733c92df08.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4919_JPG.rf.d34e9331a71867c724efff300ed11c16.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000111_JPG.rf.ab4ed3daddc53a21017eec71afcdb15d_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/20_jpg.rf.460d83b48fab5cfd375c55c8ce5bfa2b.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000054_jpg.rf.2f23611817ac6aca44a74fe3e1483aeb_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000078_JPG_jpg.rf.5b401c9371f5a53e15a2a7f3a2d3d917.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000091_jpg.rf.53a9d02074f73b853be284fedaef1658.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000490.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000206.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000050_JPG.rf.344d00bccede12dc56716613538ba70a_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000063_jpg.rf.206563f196b6b448456b6e22f6e4683c.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000059_jpg.rf.125f60cd509f1aaa148e2e543bd35488_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000015_jpg.rf.86d6b3e9a1c78d9c62630c52238026d7_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000110_JPG.rf.58f085b607a5433a0a0a64bc3f54750a.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000013.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000057_JPG.rf.bd9dc1bbef5995c1474f73abd7310419_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000041_JPG.rf.6a4413de3426e994050bed89e32becd2_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000069_jpg.rf.30cad46efae7e4e32ace995b5add97e0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000021_JPG.rf.89d63a8d463a4820c1247bbe3013ed48.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000059_jpg.rf.7194db66729443583bba7c5b2ece1bf3_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000105_JPG.rf.a0210840727d8b6ed1e715734261f60b.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000080_jpg.rf.16562dc1ba7744c2beb6a13ea486eefb_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000065_jpg.rf.48e670b619ce9b09f2f21f298cdca522.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000090_jpg.rf.ea06ffd03250a44cb11ed647ff6c211c.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000005_JPG.rf.24425e9dbfb6c79b42b1de78ac57c324_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000369.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/118-4-_jpg.rf.78c81bfc84364d849c967eead4745d83.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000016_jpg.rf.78be6070e19acb6d4206b07c49cfe1e4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000061_jpg.rf.7779d6ce157b1c650648a2e9de0b5d38_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000029_jpg.rf.e04d5945eb1439aaf062974756da20cd.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000039_jpg.rf.d8488b95e25bf63dd66548d11b2596b6.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000047_jpg.rf.722346785de0e6af2fe693f0a9e7c7a2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000070_jpg.rf.03477027b2e3d800b0b3bd734c049f32_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000003_jpg.rf.4fee21529a27b262670330b7f4aee02c_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000056_jpg.rf.3160ea007c8b7f002e03da0d91cda916.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000009_JPG_jpg.rf.70bfad3af9af85f59f72d94c642a1ad4_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000059_jpg.rf.7194db66729443583bba7c5b2ece1bf3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000039_JPG.rf.46c9ef448b79d140a5f1c093550ff9f9.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000352.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_5049_JPG.rf.91676f3d05686f10bc0c2d32cbe45c96.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000069_JPG.rf.cf5796ce70a3e051b6c95dc82fe30c13.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/9000077_jpg.rf.324178077dc2b32de5a197f1602c2817.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000041_JPG.rf.6a4413de3426e994050bed89e32becd2_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000019_jpg.rf.4d068af7c9fc06933fa7d8ddfe5e5587_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000059_jpg.rf.0d88e63ee80308de7f58723803220c1f_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000124_JPG.rf.9f616b2f82b3b60688ed109c15d455b3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000118_JPG.rf.a32ae4b525c0b9c333248eaa6302a931.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000184.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/35-2-_jpg.rf.19a060d6644f8dfe654b7c41f9a9dcfe_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000041_JPG.rf.6a4413de3426e994050bed89e32becd2_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/mcdonalds-empty-cola-cup-with-paper-straw-mcdonalds-is-the-worlds-largest-chain-of-hamburger-fast-food-restaurants-W9YFGJ-transformed_jpg.rf.03d9d09d620bee82a84ee3460c1a48b2_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000386.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/117-2-_jpg.rf.2739d91e982188929fb8f4a64540d54b.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/9000010_jpg.rf.e021e326de8489308443c3755579c2fd.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000492.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/47_jpg.rf.90d50076ca18fea263af298ab02f4134.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000366.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000069.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000055_jpg.rf.bb7501cb6e605317e1b70a3cbfec0780.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/reusable-cup-with-paper-straw-womans-handzero-waste-lifestyle_377884-382_jpg.rf.e2a66ede5b35617e5f74c710f69617a5_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/IMG_4922_JPG_jpg.rf.ca3a95d60e818cd5f5f9fa1ab6c7b6e3_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/119-3-_jpg.rf.ead46c6b3877cbdb22e30592d4ad9845.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000023_JPG.rf.0d43c9978b915812fb1888496f68cd75.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4868_JPG.rf.3e42948997f641da25ab729ba71d5f36.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000271.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000056_jpg.rf.6ee5dc3aab1c0ba032abd3d08e6b8e9d.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000127_JPG.rf.da5be93c943766123144a46a38675088_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/108-4-_jpg.rf.593f6ef5c8aaa96e4c1ca6e4477da8b2_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000260.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12_jpg.rf.9e64d4ec9ef22acbb51eeccc0f876bcd.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000068_JPG.rf.473d1340c06afb71f5d8e4d6f5de66b3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000037_JPG_jpg.rf.8d61d4383778937ef5eb0729adef9d06.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000018_jpg.rf.3c7c2e5f5fdf36ca3fcc0c2420673e32_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/9000040_jpg.rf.334a8485d164a35f0831318054f272bc.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000098_jpg.rf.e5a1665097cdfdc1215d053cf0e50d41.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000092_JPG.rf.a8f975830abd7a108859f347f25598f9_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000054_jpg.rf.82a56ae9ec544ace7f0b194f72419bc6_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000516.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000009_JPG_jpg.rf.70bfad3af9af85f59f72d94c642a1ad4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000060.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000009_JPG_jpg.rf.acd5828a16ac889fa4cef266de574c04_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000018_jpg.rf.3c7c2e5f5fdf36ca3fcc0c2420673e32_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000085_JPG.rf.fa571584a44399d0456f39becdb5b230_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000057_jpg.rf.1412c6b9f95aa25fb49d691250a9b8ca.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/8000099_jpg.rf.f73af5bd219bce6b43ff29790b0ca656_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000102_JPG.rf.a01070aa3e46790848a18339d8f29721_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000010_jpg.rf.97bbb3b9389f6a2cf189d606ada8d25e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000077_JPG.rf.07c472e7a163f86c17d3ff483ade0a89.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000477.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000097_jpg.rf.65d4f8e09fb5305d78bdd31cd0feaa30.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000039_JPG.rf.6ac5cb5a978b26e48900719386f67c22.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/9000020_jpg.rf.a311c90f84f41a91a12535ba484663de_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000056_JPG.rf.b40b1aaca1a14e673ee16a218bb84201_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000070_JPG.rf.6886a154f89e447537b29588577e3cd6.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000152.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000022_JPG.rf.1d48e2ecaa1421655bf7d5e945d320b4_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000055_jpg.rf.ec7015b4cd7ffafbed3b37a817430746_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/14000052_jpg.rf.d93d0ed7d06e13529e2fb1c20f90d917.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/19-2-_jpg.rf.cfb45fb5ec28a43afe27ab34a8eaf6f8.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000076_jpg.rf.a6f028f70879b585d45d14c726af7b46.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000065_jpg.rf.f971cb875068e23635c6912eb0476222_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000035_JPG.rf.64b9297f72298955ff3c1892e698bee6_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000018_jpg.rf.ef24fa9f9d4ab1116c40da3b8753a452_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000055_JPG.rf.2001eba4f681bd196d980868a189e4c4_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000108_JPG.rf.10871f11f9f7f225499892ebc8986db7_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000095_jpg.rf.0666392a6badca35a930c63622eaf31e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000025_jpg.rf.72fe9551738c7dbb002e7132989dba30.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000015_jpg.rf.230ad17a0d923f083e7ce6aa50ae1d24_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000008.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4876_JPG.rf.e01212e9b631ca54cda9a0fc935ddc9c_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000127.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000037_JPG.rf.8b7f7fd3c17eb52065551914a09141f2_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000114_JPG.rf.fc346afb1b7870e68486435e76c7b8f2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000118.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000035_JPG.rf.64b9297f72298955ff3c1892e698bee6_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000026_jpg.rf.8d1573707aa5900c1e9f59570e83464e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000032_jpg.rf.af0e698ceceef5c9d0242474748b515e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/IMG_4922_JPG_jpg.rf.ca3a95d60e818cd5f5f9fa1ab6c7b6e3_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000096_JPG.rf.dc385dbf252d9c55d64db1c8a6353d1a_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000060_jpg.rf.f36febe9e287109171ec78c579d7d1b1_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000018_JPG_jpg.rf.c733493a70145a9e195f706d9bdd183a_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000226.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000254.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000102_JPG.rf.a01070aa3e46790848a18339d8f29721_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000029_jpg.rf.3c553a5f9f91ced137be5ee2ef8334bf_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4862_JPG.rf.6ffb2eef830618f992cd215e29051485_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000011_jpg.rf.95186b47c50ed41f564fafb77f132b9c_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000430.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000086_JPG.rf.34ab1155e8b52024f953da76472976a9.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000009_jpg.rf.15439969346f126ed9ecc2ca1a36d5fb_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000210.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000106.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000020_jpg.rf.6f9684fcd8098171f6f58a8b15ca28b1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000075_JPG.rf.b52b0b995d8209ce827fd15293765a16.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000049_JPG.rf.4d48022d1b984d5bfe73a43b33638505.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000090_JPG.rf.58dd7ca253a90136c01016aaa3bb8b1f.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000156.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000051_jpg.rf.39b8c63b715469f22063d57bc8195353.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000295.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000153.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000059_jpg.rf.7be926b5970dca079e98c31e8ad4101e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000048_jpg.rf.4d871babec1a2bdf083d46ddaf60336c.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000011_jpg.rf.02a1f97705abe7afaaff65a3ce9c74c8.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000498.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4948_JPG.rf.4cec287ba4a361e2f918492cdd190f32_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000370.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000027_jpg.rf.ee802b53c28178f993a474a69668c2a2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000055_jpg.rf.f147e26a6457d42c0ea7b2552ace4a88_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000059_jpg.rf.8dc4e3978437e18a0cf6edc77a3dc967_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/9000008_jpg.rf.ba86f14fae31cf9b8b62be6286ccedc5_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000015_jpg.rf.44c9a8f99794464d3a9f8aa6c3fc06a5.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_5039_JPG.rf.0c3f9e2b784f08ff32a3d0b54ec92ecf.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000084_jpg.rf.8e9131f2072ac71c09c8407bf8afb9db_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000472.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000097_jpg.rf.fc5c4d7b9dba1b8690dd9a3647cbab87.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000115_JPG.rf.ef8d9ebe8ba72fce3f5bc4d612a77c00.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000037_JPG_jpg.rf.155fc753cb0020965a3b7004500d747e_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000001_jpg.rf.2d1d15d623fde54b94304acca1281f7c_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000066_JPG.rf.0aaa612ae531db8eecd39a5c3468761b.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000003_JPG.rf.b1577e3766e8944e57228a5e1a9cf2db_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/8000082_jpg.rf.d5cc6604696df93153f8178bea422f56_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000061_JPG.rf.e8212d988d62eb47039add0bde1388c4_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000080_jpg.rf.2137fdfeacd35233b1a191702dbf21a1_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000015_JPG.rf.90141e64c830e9c2ccd1fc0286acb67c_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000316.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000024_jpg.rf.79e93483a1135261df4e992784b0c66e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000034.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000071.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/e3l2833k0lx21_jpg.rf.41fd25013e84f39a9bd6f268e52e19c8_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000236.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4898_JPG.rf.f59b8a7c73ccf25920e726ae7fb09125.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000019_JPG.rf.1a02e8cffe0b3b98231f7e33ffee8418.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000224.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000071_JPG.rf.091bbf1400906bf890940432e1c7e304.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000011_jpg.rf.95186b47c50ed41f564fafb77f132b9c.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000097_JPG.rf.7cb6ae27d2c0b355f16d7da7a31851e6_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000344.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000322.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000072_jpg.rf.421628ba41367ff434adaca26ee9655f_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000088_JPG.rf.c8c5e691bf757236393ef0db1d15bb10_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000061_jpg.rf.aa7735c75eb684b5d9540ecd75483bd0_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000058_jpg.rf.72e21cc4377fc37797f7d18ef039d52e_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000051_jpg.rf.f8ac9557e1b928b6f6cd85616972022c_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000037_JPG.rf.e5aef7caa30ed733e8d111fdd734d02f_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/14000055_jpg.rf.a1a77e7bacca4b637344bb3d17b213fc_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000099_jpg.rf.716f55cd467e5c0739d20b395fcbdc07.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000005_JPG.rf.24425e9dbfb6c79b42b1de78ac57c324_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/2000088_JPG.rf.9aa79030d9992c3cc83d738379d1ad72.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000022_JPG.rf.08cb5dde75973a926816bbe647ca9e3e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/14000074_jpg.rf.ba02cc7abb61e2d9634b9473ae3bd2d8.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000374.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000079_JPG.rf.2b2a909b175dd5fea731467dee60a881.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000046.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000057_jpg.rf.7233082ac866d1e1c72ab096a3a0865a.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/8000002_jpg.rf.0ada82d41a5152d1a79b77cbef945c76.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000097_JPG.rf.f657bcec135c21adaed2d52a0da85481.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_5068_JPG.rf.d951fa97e60626c79227d1414cf3d67d.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000098_JPG.rf.e9f5a589a2622da69447df25b36b9903_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000061_jpg.rf.b38207cd4aa539d8446fc7a1339dcf08_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000139.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000055_jpg.rf.b62e02171adf9d5b9eba87cb7af9aadb_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000464.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000007_jpg.rf.5c8d44e7a6132214745aa57e1ca48e1c.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000016_jpg.rf.389acf3f45d617b4d5b9e5d409f54a83_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000019_jpg.rf.fd09135bbde59bd3d6f935711b799d8e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000416.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/101-3-_jpg.rf.54849d0c76489288e6b790ae1764e379.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000074_jpg.rf.bc9a092ce6e0e86ab38819e6c3c306b6.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000054_jpg.rf.a1c79e3d36f4f3e6c6a5ff16c2db21a1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000167.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000302.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000175.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/101-4-_jpg.rf.28c30960e1fee6abff609343f5e559fd.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000085_jpg.rf.5a23c6e362f38b067b62f6c2e77b7bed.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000108_JPG.rf.10871f11f9f7f225499892ebc8986db7.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000335.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000077.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000008_JPG.rf.294af3c767d7d6f89832ef53cfc18b87_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000008_jpg.rf.f97e08741f4c896fc0a388f63619cd06.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000121_JPG.rf.950f0a654b9de44a80cca689844be087.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000078_JPG_jpg.rf.3804147a0c76a30b5dca8092c6024b18_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000107_JPG.rf.94665032a88c2e76901580f5e95d6a76.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000056_JPG.rf.93f4f41f72578b33042017da495768ed_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/IMG_4922_JPG_jpg.rf.ca3a95d60e818cd5f5f9fa1ab6c7b6e3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000056_JPG.rf.b40b1aaca1a14e673ee16a218bb84201.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000282.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000017_JPG.rf.720e47fb2c3d8be3994dbb41d49c0cbb_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000063_JPG.rf.6b495e60eb5197b98ce7434cec70f7d1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000081_jpg.rf.46349092b46cadc11e61dd63b1ff0e9a.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000014_JPG.rf.3e32cd388ee343d7c65f3f656c8dc065.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/9000056_jpg.rf.65af827318858296ff7f12276f7c0b64.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4876_JPG.rf.e01212e9b631ca54cda9a0fc935ddc9c_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000107_JPG.rf.94665032a88c2e76901580f5e95d6a76_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000070_JPG.rf.6158d08cb473eb5c49ecb928e1fd0a8e_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000071_JPG.rf.a6a91aa069cb8516c2a8348817a851a0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000423.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000359.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000280.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000047_JPG.rf.98fc987a35f5456330a543e057989a38.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000010_jpg.rf.cce68f7dce2285fc52fc8ba68e543f9e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000456.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000161.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000039_jpg.rf.dfa52be5a37e5e97be23845da7e588bb_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/IMG_5050_JPG_jpg.rf.f2a59223d3e70ae3ac894a2f23427851_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000018_jpg.rf.e17daa7a548c2fa23e6ffcad54aba23b.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000189.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4879_JPG.rf.ead0c40b9b5e5471191657e1a0124da7_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/2000042_JPG.rf.01e882a16980029dcaa76056b51ecd24.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000398.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000022_JPG.rf.1d48e2ecaa1421655bf7d5e945d320b4_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/29-3-_jpg.rf.0704fac61273896c371faea446e6f4b7_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000240.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000075_JPG.rf.371cff3fb0d59890fd957dfba3f3e898_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000011_JPG.rf.753279452a4c7983b4dfeb0c4dd258b6.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000258.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000256.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000136_JPG.rf.afc19831d68c25ea5286a605366857e3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000422.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000029_jpg.rf.3c553a5f9f91ced137be5ee2ef8334bf_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/28_jpg.rf.4858b7dc0636e220e1e20a8f4db2023e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000081_JPG.rf.a94d6107cb6c6aa81c824880a6e8d8c9_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_4965_JPG.rf.910c71eee92b8c1c2c61bc9b546208b6_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000126.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000049_JPG.rf.6b83b56d8282790c24afcfc58eebc6a6.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000039_JPG.rf.e9e8f6c22a7910d1b4d8e78acbd648c9_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000108_JPG.rf.10871f11f9f7f225499892ebc8986db7_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000015_jpg.rf.86d6b3e9a1c78d9c62630c52238026d7_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000076_jpg.rf.9d4895e46bf508dd23dd7b67643876cc.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000027_jpg.rf.b9478e6e21138748512f0d3bc92f98bf_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000102_JPG_jpg.rf.9db5692910c4398495ce8d943b4c261c_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000006.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000004_jpg.rf.968f2e164950eb66cede497ae72a17da.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000096_jpg.rf.7c6bedd3708771efbb6ae085f6286f13_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/8000082_jpg.rf.d5cc6604696df93153f8178bea422f56_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/DnILtx1WsAAHAoc_jpg.rf.2d5cf8a645aac8ebbec09513e9847d9a_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000040_JPG.rf.8ce95d8a1970a9bbb83477a41cb05517.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000007_jpg.rf.4433baf9c84ed7c7f756b41ca2b22f2e_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/8000071_jpg.rf.19a3f8e03530ab453da600affc47a0cc_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/8000066_jpg.rf.b83d6ba59c9db0fdbbbf255e790ade56.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000061_JPG.rf.e8212d988d62eb47039add0bde1388c4_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_5048_JPG.rf.d835e83680cf78b7b3986cefbb8f9d6a.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000061_jpg.rf.8cfc8875fec0b216f186929de7a48dab_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000056.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000137_JPG.rf.7f8f9d9a972843b74bd3d9e63bcbd6cb.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000232.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000281.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000095_JPG.rf.37fce843784c572511c0c91a407260e9_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000061_jpg.rf.aa7735c75eb684b5d9540ecd75483bd0_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/14000032_jpg.rf.9503bdc48620fcb0a73abc292146baff.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000051_jpg.rf.f8ac9557e1b928b6f6cd85616972022c_webcam_0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000076_jpg.rf.b8791ed7a41fd35d1282ab5a0f6e0da7.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000091_JPG.rf.30b2b7214dbb033f53a6a7c38adbc58a.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000034_JPG.rf.cb1f16a29cffe1e2258db8dc0a62355f.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000056_jpg.rf.f750e73567c91610a716af78ed696dc0.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000041_JPG.rf.2ab232e7ec3703b80a3508e33dc21c07_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000015_JPG.rf.46fc5def1434c1dd8c66ec11f8b492a7.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000006_jpg.rf.a3c08bd607ddebcce77e5a7e4afeff63.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_5066_JPG.rf.1cc9c8ab829529980a09b67182e5e81f_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000314.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000028_jpg.rf.065f43fc5efba5fe9518c16a25454056.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000502.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000088.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000028_jpg.rf.065f43fc5efba5fe9518c16a25454056_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000022_JPG_jpg.rf.3c6f29a466b040fce166b513993bc512.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000050.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/12000028_jpg.rf.5654a6ca23a5106493bc198fa6b7b3af.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000098_JPG.rf.5c7fc087c134b0f8ea0900776661581b.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000061_jpg.rf.7779d6ce157b1c650648a2e9de0b5d38_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000183.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000094_jpg.rf.bf70acc9d6ad236c23f0f9bd6b779ab1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000180.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/15000046_jpg.rf.f95b2edb26e8d60a1657b3a8a5275ee7.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000071_JPG.rf.445727a1d46d57ec83b57b07626b6380_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/14000009_jpg.rf.f2280bbdfdec19a51cb27517e8ad8ec4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000111_JPG.rf.f094396c7be3431dddcdf37b5d5c04e4_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000069_JPG.rf.a0cef55bfb88ce202ec2f200151f5d84.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000495.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000480.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000111.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/8000086_jpg.rf.927b8d9c4194f371bcfdaf030ea3729f.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000033_jpg.rf.3f358224c36f164b8b3e0843a68803ef.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/2000068_JPG.rf.0887a6cdf545cd6e129a0c2566bacc5d_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_5003_JPG.rf.d31943153a40c0ff3dd4d236116ffef5_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000027_jpg.rf.13b71c45f89f3952dea13ff000d1e436_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000507.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000410.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/rty0srprsti31_jpg.rf.1dc31ee077d52b962a02007676f5a740_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/9000050_jpg.rf.2f894e078f87f126a8306fe87afe4cd4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000073.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/28-2-_jpg.rf.068adfe53d4a297ea6e6062bfd28f106_webcam_3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000015.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/throwing-crumpled-paper-paper-glass-paper-straw-and-plastic-bag-into-the-trash-can-in-home-or-office-free-video_jpg.rf.e8c857d491e207f8b881971ed33ebf4b_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/14000025_jpg.rf.4ad092cd0782605c0f707e64c07c7be1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000045.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000022_JPG.rf.1d48e2ecaa1421655bf7d5e945d320b4_webcam_1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000099.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000201.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/14000034_jpg.rf.fdbf0371d72220bb9683cde8df529c09.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/IMG_5050_JPG_jpg.rf.f2a59223d3e70ae3ac894a2f23427851_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_5066_JPG.rf.1cc9c8ab829529980a09b67182e5e81f.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/11000054_jpg.rf.9d2760ae155e81b1ba87eea5a032dd5e.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000025_jpg.rf.b607018861077e04d4b487baafecaa7a.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000367.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/3IMG_5063_JPG.rf.a96b7be1746b01613ff5c164eea581b3.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/6000045_JPG.rf.3bc5864ca9ff079e67cbf23db396f567.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/7000020_JPG.rf.0dbe9ad2507345d5be88732504f00365.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/000037_JPG_jpg.rf.47dc28275fbc694b110913ce5d094cb2_webcam_2.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/1000117_JPG.rf.7d531d83f1f3a909b367607b2322dd72.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/30_jpg.rf.c5f1719e709bc655e252e21821a53520.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000350.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/4000050_JPG.rf.344d00bccede12dc56716613538ba70a.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/10000017_jpg.rf.a600e50317e4c084b833bf1f8d6f77d1.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000431.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000141.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/5000112_JPG.rf.1603714aa26a5869a9c90d14fc0e9455.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/nppoi4iy6ue11_jpg.rf.cdb73b5f4f44f5990b65de4ee433833d_webcam_4.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/13000050_jpg.rf.11ea2c51928d3b8af94b14800306fb95.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/valid/images/Places365_val_00000030.jpg',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/8000019_jpg.rf.c7070e20218deef57e72bb9aaa327d95_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/10000090_jpg.rf.2e6fdaad6799c2fa1c714a6d3fea5c39.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000598.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/4000058_JPG.rf.c90f28d2dec46a9cd2e04316be3d8616_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/13000074_jpg.rf.8b081f8a9083dc540d610a90015d80bb.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/31_jpg.rf.110780b3ae3a7c9aef3494306cf5d0df.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/1000101_JPG.rf.3ac211b4b2f4728ff64baab1b2e68ffc_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/13000047_jpg.rf.a93d6b1ccf477e4a02d547b8e0172915.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000716.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/000009_JPG_jpg.rf.acd5828a16ac889fa4cef266de574c04_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/7000058_JPG.rf.383071f026eb73dbe40380d315ce0370.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000651.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/14000020_jpg.rf.acee02b47dacbcdc3b132c20c409c8e7.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/3IMG_4875_JPG.rf.3be12a7a8750ca38297ec9d006a504c3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/000102_JPG_jpg.rf.9db5692910c4398495ce8d943b4c261c_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000963.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/1000092_JPG.rf.a8f975830abd7a108859f347f25598f9_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/14000037_jpg.rf.7cc6404ad4de686c8bf2369cc2d65544.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/11000027_jpg.rf.df3808c85b4877ea92d4c4689743def8_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/25_jpg.rf.9b2e087d7ab905d569b20f27a5c3d8d4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/e3l2833k0lx21_jpg.rf.41fd25013e84f39a9bd6f268e52e19c8_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/14000055_jpg.rf.a1a77e7bacca4b637344bb3d17b213fc_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/6000068_JPG.rf.0d38096f64d7a9e39e03e7250b6e48a1_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/7000066_JPG.rf.1e3af420e0ed7c79cb69a9c0a0dba39f_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/5000085_JPG.rf.fa571584a44399d0456f39becdb5b230_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/1000096_JPG.rf.dc385dbf252d9c55d64db1c8a6353d1a_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/000078_JPG_jpg.rf.5738ad1403e10f8e88015a36d083f298_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/11000019_jpg.rf.53c6e9c67c75b1319315ada69ad55bae.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/7000047_JPG.rf.8da1b32d234395419d4aeba053f71335.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/8000089_jpg.rf.ccef66772eec89927f05b5433ccb5371_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/3IMG_4889_JPG.rf.83ba090e9fbc8ca96eb41a4713e0ce6e.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/6000068_JPG.rf.0d38096f64d7a9e39e03e7250b6e48a1_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/10000064_jpg.rf.fa66c30229eda3d1841c4e92e59dcf26.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000967.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/3IMG_5064_JPG.rf.29519d4f07232b17a8ca3fb5f6be3264_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/12000087_jpg.rf.2e165e03aaf148e4d8b8c603b1009f50_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/3IMG_4898_JPG.rf.f59b8a7c73ccf25920e726ae7fb09125_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000800.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/9000071_jpg.rf.a63699c5887d37f3b9c3aa47d22c0b1e_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/7000101_JPG.rf.169578d1764bde32cb0a21b396c84976.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/5000099_JPG.rf.d06ae45806a3a30be4d7ca45a60df8e3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/2000010_JPG.rf.024854d3e6262db77092cea1471cd9e9_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/000059_jpg.rf.edbe31d00d09c0eaae77509144d7ac22_webcam_0.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/e3l2833k0lx21_jpg.rf.41fd25013e84f39a9bd6f268e52e19c8_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/14000064_jpg.rf.66a28ae63e4429c52e9465c7c007fe0b.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/11000079_jpg.rf.f46d7d77071392d8064e5a5c1dfad5a4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000569.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000740.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/12000016_jpg.rf.389acf3f45d617b4d5b9e5d409f54a83_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000715.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/27-4-_jpg.rf.fd2325e740473858521336a0934a91db.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000732.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/000037_JPG_jpg.rf.d91ff15e58609e8999b39e991f35b55f.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/3IMG_4911_JPG.rf.f08935b79560921d88f05a806bf7b8b2_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/14000042_jpg.rf.1ed32d6d3fa6dff29e8c1df951dd151b.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/3IMG_4965_JPG.rf.910c71eee92b8c1c2c61bc9b546208b6.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000958.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/13000052_jpg.rf.67e6577e9ae1bf8d5e548363a9b51f27.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/000015_jpg.rf.65773f9ec14ea994db097b610695b7a8.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000989.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/107-2-_jpg.rf.843950c281a3bd0370e1e51c5407fa51.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/13000062_jpg.rf.2ff54b66669d27b2d74a1d5ddb7e6ac8_webcam_3.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/6000017_JPG.rf.720e47fb2c3d8be3994dbb41d49c0cbb_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/8000053_jpg.rf.bc104282c9778d25bdeb3d80bb3f7d36_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/5000045_JPG.rf.47cccd31d9c9c59b15a611437fd2cc7d.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/10000095_jpg.rf.0666392a6badca35a930c63622eaf31e_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000697.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000575.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000832.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/15000066_jpg.rf.9eedc94d97f999a6dedd283deddbe68c_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000796.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/12000011_jpg.rf.d7d3d2fd177896c01fc46febaa3d492b.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000620.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/4000036_JPG.rf.2c736b05a1f31cfdb8a123d0227919b8.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/000051_jpg.rf.5d73f74996ac5876e9972d210ddc0f24_webcam_4.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/6000074_JPG.rf.ebdd6daa27a45e6f2277fd5f5affd512.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/8000055_jpg.rf.1f321faebdcede455e20963cc4903406_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/13000094_jpg.rf.13a62f682881e9b2b2091516e24a368d.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/9000047_jpg.rf.34626e9452b5fc026a6082508f2c3eec.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/000000_jpg.rf.03d15b216b093037395fef1d5cb594bf_webcam_1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/11000065_jpg.rf.f971cb875068e23635c6912eb0476222_webcam_2.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000686.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000773.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/3IMG_4902_JPG.rf.53a977b6c5952390be4417fdbbc554e1.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/8000026_jpg.rf.c267d772eb240b3f49b2e1c6c221b83a.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/8000015_jpg.rf.9be8348d1c8f840ed70270e0019b4690.txt',\n",
       " '/kaggle/working/TACO_with_hard_negatives/test/labels/Places365_val_00000750.txt',\n",
       " ...]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "from_dir = '/kaggle/input/taco-with-hard-negatives'\n",
    "to_dir = '/kaggle/working/'\n",
    "\n",
    "copy_tree(from_dir, to_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2e6190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:17:27.192889Z",
     "iopub.status.busy": "2025-06-25T04:17:27.192489Z",
     "iopub.status.idle": "2025-06-25T04:18:45.802461Z",
     "shell.execute_reply": "2025-06-25T04:18:45.801560Z"
    },
    "papermill": {
     "duration": 78.614641,
     "end_time": "2025-06-25T04:18:45.803925",
     "exception": false,
     "start_time": "2025-06-25T04:17:27.189284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.159-py3-none-any.whl.metadata (37 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.3)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Downloading ultralytics-8.3.159-py3-none-any.whl (1.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\r\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.159 ultralytics-thop-2.0.14\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950124f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:18:45.853646Z",
     "iopub.status.busy": "2025-06-25T04:18:45.852749Z",
     "iopub.status.idle": "2025-06-25T04:18:46.619530Z",
     "shell.execute_reply": "2025-06-25T04:18:46.618742Z"
    },
    "papermill": {
     "duration": 0.792468,
     "end_time": "2025-06-25T04:18:46.620910",
     "exception": false,
     "start_time": "2025-06-25T04:18:45.828442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#converting to object detection dataset\n",
    "import os\n",
    "\n",
    "base_dir = \"/kaggle/working/TACO_with_hard_negatives\"  \n",
    "\n",
    "subsets = ['train', 'test', 'valid']\n",
    "\n",
    "def polygon_to_bbox(points):\n",
    "    \"\"\"Convert list of (x, y) points to bounding box in YOLO format\"\"\"\n",
    "    xs = points[::2]\n",
    "    ys = points[1::2]\n",
    "    x_min = min(xs)\n",
    "    x_max = max(xs)\n",
    "    y_min = min(ys)\n",
    "    y_max = max(ys)\n",
    "\n",
    "    x_center = (x_min + x_max) / 2\n",
    "    y_center = (y_min + y_max) / 2\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "for subset in subsets:\n",
    "    label_dir = os.path.join(base_dir, subset, 'labels')\n",
    "    for fname in os.listdir(label_dir):\n",
    "        if not fname.endswith(\".txt\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(label_dir, fname)\n",
    "        new_lines = []\n",
    "\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = list(map(float, line.strip().split()))\n",
    "                class_id = int(parts[0])\n",
    "                polygon_points = parts[1:]\n",
    "                x_center, y_center, width, height = polygon_to_bbox(polygon_points)\n",
    "                new_line = f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
    "                new_lines.append(new_line)\n",
    "\n",
    "        # Overwrite the file with detection-format annotations\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write('\\n'.join(new_lines) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd98744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T04:18:46.667814Z",
     "iopub.status.busy": "2025-06-25T04:18:46.667341Z",
     "iopub.status.idle": "2025-06-25T11:41:51.714821Z",
     "shell.execute_reply": "2025-06-25T11:41:51.713725Z"
    },
    "papermill": {
     "duration": 26585.073124,
     "end_time": "2025-06-25T11:41:51.717036",
     "exception": false,
     "start_time": "2025-06-25T04:18:46.643912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Ultralytics 8.3.159 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.3, copy_paste_mode=flip, cos_lr=True, cutmix=0.2, data=/kaggle/working/TACO_with_hard_negatives/data.yaml, degrees=20.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.2, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=/kaggle/input/rtdetr/pytorch/default/1/rtdetr_last.pt, momentum=0.9, mosaic=1.0, multi_scale=False, name=v2_rtdetr, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=50, perspective=0.0005, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=/kaggle/input/rtdetr/pytorch/default/1/rtdetr_last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/v2_rtdetr, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.8, seed=42, shear=10.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.01, workers=8, workspace=None\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 17.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7353227  ultralytics.nn.modules.head.RTDETRDecoder    [25, [256, 256, 256]]         \n",
      "rt-detr-l summary: 457 layers, 32,857,451 parameters, 32,857,451 gradients, 108.1 GFLOPs\n",
      "\n",
      "Transferred 941/941 items from pretrained weights\n",
      "Freezing layer 'model.0.stem1.conv.weight'\n",
      "Freezing layer 'model.0.stem1.bn.weight'\n",
      "Freezing layer 'model.0.stem1.bn.bias'\n",
      "Freezing layer 'model.0.stem2a.conv.weight'\n",
      "Freezing layer 'model.0.stem2a.bn.weight'\n",
      "Freezing layer 'model.0.stem2a.bn.bias'\n",
      "Freezing layer 'model.0.stem2b.conv.weight'\n",
      "Freezing layer 'model.0.stem2b.bn.weight'\n",
      "Freezing layer 'model.0.stem2b.bn.bias'\n",
      "Freezing layer 'model.0.stem3.conv.weight'\n",
      "Freezing layer 'model.0.stem3.bn.weight'\n",
      "Freezing layer 'model.0.stem3.bn.bias'\n",
      "Freezing layer 'model.0.stem4.conv.weight'\n",
      "Freezing layer 'model.0.stem4.bn.weight'\n",
      "Freezing layer 'model.0.stem4.bn.bias'\n",
      "Freezing layer 'model.1.m.0.conv.weight'\n",
      "Freezing layer 'model.1.m.0.bn.weight'\n",
      "Freezing layer 'model.1.m.0.bn.bias'\n",
      "Freezing layer 'model.1.m.1.conv.weight'\n",
      "Freezing layer 'model.1.m.1.bn.weight'\n",
      "Freezing layer 'model.1.m.1.bn.bias'\n",
      "Freezing layer 'model.1.m.2.conv.weight'\n",
      "Freezing layer 'model.1.m.2.bn.weight'\n",
      "Freezing layer 'model.1.m.2.bn.bias'\n",
      "Freezing layer 'model.1.m.3.conv.weight'\n",
      "Freezing layer 'model.1.m.3.bn.weight'\n",
      "Freezing layer 'model.1.m.3.bn.bias'\n",
      "Freezing layer 'model.1.m.4.conv.weight'\n",
      "Freezing layer 'model.1.m.4.bn.weight'\n",
      "Freezing layer 'model.1.m.4.bn.bias'\n",
      "Freezing layer 'model.1.m.5.conv.weight'\n",
      "Freezing layer 'model.1.m.5.bn.weight'\n",
      "Freezing layer 'model.1.m.5.bn.bias'\n",
      "Freezing layer 'model.1.sc.conv.weight'\n",
      "Freezing layer 'model.1.sc.bn.weight'\n",
      "Freezing layer 'model.1.sc.bn.bias'\n",
      "Freezing layer 'model.1.ec.conv.weight'\n",
      "Freezing layer 'model.1.ec.bn.weight'\n",
      "Freezing layer 'model.1.ec.bn.bias'\n",
      "Freezing layer 'model.2.conv.weight'\n",
      "Freezing layer 'model.2.bn.weight'\n",
      "Freezing layer 'model.2.bn.bias'\n",
      "Freezing layer 'model.3.m.0.conv.weight'\n",
      "Freezing layer 'model.3.m.0.bn.weight'\n",
      "Freezing layer 'model.3.m.0.bn.bias'\n",
      "Freezing layer 'model.3.m.1.conv.weight'\n",
      "Freezing layer 'model.3.m.1.bn.weight'\n",
      "Freezing layer 'model.3.m.1.bn.bias'\n",
      "Freezing layer 'model.3.m.2.conv.weight'\n",
      "Freezing layer 'model.3.m.2.bn.weight'\n",
      "Freezing layer 'model.3.m.2.bn.bias'\n",
      "Freezing layer 'model.3.m.3.conv.weight'\n",
      "Freezing layer 'model.3.m.3.bn.weight'\n",
      "Freezing layer 'model.3.m.3.bn.bias'\n",
      "Freezing layer 'model.3.m.4.conv.weight'\n",
      "Freezing layer 'model.3.m.4.bn.weight'\n",
      "Freezing layer 'model.3.m.4.bn.bias'\n",
      "Freezing layer 'model.3.m.5.conv.weight'\n",
      "Freezing layer 'model.3.m.5.bn.weight'\n",
      "Freezing layer 'model.3.m.5.bn.bias'\n",
      "Freezing layer 'model.3.sc.conv.weight'\n",
      "Freezing layer 'model.3.sc.bn.weight'\n",
      "Freezing layer 'model.3.sc.bn.bias'\n",
      "Freezing layer 'model.3.ec.conv.weight'\n",
      "Freezing layer 'model.3.ec.bn.weight'\n",
      "Freezing layer 'model.3.ec.bn.bias'\n",
      "Freezing layer 'model.4.conv.weight'\n",
      "Freezing layer 'model.4.bn.weight'\n",
      "Freezing layer 'model.4.bn.bias'\n",
      "Freezing layer 'model.5.m.0.conv1.conv.weight'\n",
      "Freezing layer 'model.5.m.0.conv1.bn.weight'\n",
      "Freezing layer 'model.5.m.0.conv1.bn.bias'\n",
      "Freezing layer 'model.5.m.0.conv2.conv.weight'\n",
      "Freezing layer 'model.5.m.0.conv2.bn.weight'\n",
      "Freezing layer 'model.5.m.0.conv2.bn.bias'\n",
      "Freezing layer 'model.5.m.1.conv1.conv.weight'\n",
      "Freezing layer 'model.5.m.1.conv1.bn.weight'\n",
      "Freezing layer 'model.5.m.1.conv1.bn.bias'\n",
      "Freezing layer 'model.5.m.1.conv2.conv.weight'\n",
      "Freezing layer 'model.5.m.1.conv2.bn.weight'\n",
      "Freezing layer 'model.5.m.1.conv2.bn.bias'\n",
      "Freezing layer 'model.5.m.2.conv1.conv.weight'\n",
      "Freezing layer 'model.5.m.2.conv1.bn.weight'\n",
      "Freezing layer 'model.5.m.2.conv1.bn.bias'\n",
      "Freezing layer 'model.5.m.2.conv2.conv.weight'\n",
      "Freezing layer 'model.5.m.2.conv2.bn.weight'\n",
      "Freezing layer 'model.5.m.2.conv2.bn.bias'\n",
      "Freezing layer 'model.5.m.3.conv1.conv.weight'\n",
      "Freezing layer 'model.5.m.3.conv1.bn.weight'\n",
      "Freezing layer 'model.5.m.3.conv1.bn.bias'\n",
      "Freezing layer 'model.5.m.3.conv2.conv.weight'\n",
      "Freezing layer 'model.5.m.3.conv2.bn.weight'\n",
      "Freezing layer 'model.5.m.3.conv2.bn.bias'\n",
      "Freezing layer 'model.5.m.4.conv1.conv.weight'\n",
      "Freezing layer 'model.5.m.4.conv1.bn.weight'\n",
      "Freezing layer 'model.5.m.4.conv1.bn.bias'\n",
      "Freezing layer 'model.5.m.4.conv2.conv.weight'\n",
      "Freezing layer 'model.5.m.4.conv2.bn.weight'\n",
      "Freezing layer 'model.5.m.4.conv2.bn.bias'\n",
      "Freezing layer 'model.5.m.5.conv1.conv.weight'\n",
      "Freezing layer 'model.5.m.5.conv1.bn.weight'\n",
      "Freezing layer 'model.5.m.5.conv1.bn.bias'\n",
      "Freezing layer 'model.5.m.5.conv2.conv.weight'\n",
      "Freezing layer 'model.5.m.5.conv2.bn.weight'\n",
      "Freezing layer 'model.5.m.5.conv2.bn.bias'\n",
      "Freezing layer 'model.5.sc.conv.weight'\n",
      "Freezing layer 'model.5.sc.bn.weight'\n",
      "Freezing layer 'model.5.sc.bn.bias'\n",
      "Freezing layer 'model.5.ec.conv.weight'\n",
      "Freezing layer 'model.5.ec.bn.weight'\n",
      "Freezing layer 'model.5.ec.bn.bias'\n",
      "Freezing layer 'model.6.m.0.conv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.conv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.conv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.conv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.conv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.conv2.bn.bias'\n",
      "Freezing layer 'model.6.m.1.conv1.conv.weight'\n",
      "Freezing layer 'model.6.m.1.conv1.bn.weight'\n",
      "Freezing layer 'model.6.m.1.conv1.bn.bias'\n",
      "Freezing layer 'model.6.m.1.conv2.conv.weight'\n",
      "Freezing layer 'model.6.m.1.conv2.bn.weight'\n",
      "Freezing layer 'model.6.m.1.conv2.bn.bias'\n",
      "Freezing layer 'model.6.m.2.conv1.conv.weight'\n",
      "Freezing layer 'model.6.m.2.conv1.bn.weight'\n",
      "Freezing layer 'model.6.m.2.conv1.bn.bias'\n",
      "Freezing layer 'model.6.m.2.conv2.conv.weight'\n",
      "Freezing layer 'model.6.m.2.conv2.bn.weight'\n",
      "Freezing layer 'model.6.m.2.conv2.bn.bias'\n",
      "Freezing layer 'model.6.m.3.conv1.conv.weight'\n",
      "Freezing layer 'model.6.m.3.conv1.bn.weight'\n",
      "Freezing layer 'model.6.m.3.conv1.bn.bias'\n",
      "Freezing layer 'model.6.m.3.conv2.conv.weight'\n",
      "Freezing layer 'model.6.m.3.conv2.bn.weight'\n",
      "Freezing layer 'model.6.m.3.conv2.bn.bias'\n",
      "Freezing layer 'model.6.m.4.conv1.conv.weight'\n",
      "Freezing layer 'model.6.m.4.conv1.bn.weight'\n",
      "Freezing layer 'model.6.m.4.conv1.bn.bias'\n",
      "Freezing layer 'model.6.m.4.conv2.conv.weight'\n",
      "Freezing layer 'model.6.m.4.conv2.bn.weight'\n",
      "Freezing layer 'model.6.m.4.conv2.bn.bias'\n",
      "Freezing layer 'model.6.m.5.conv1.conv.weight'\n",
      "Freezing layer 'model.6.m.5.conv1.bn.weight'\n",
      "Freezing layer 'model.6.m.5.conv1.bn.bias'\n",
      "Freezing layer 'model.6.m.5.conv2.conv.weight'\n",
      "Freezing layer 'model.6.m.5.conv2.bn.weight'\n",
      "Freezing layer 'model.6.m.5.conv2.bn.bias'\n",
      "Freezing layer 'model.6.sc.conv.weight'\n",
      "Freezing layer 'model.6.sc.bn.weight'\n",
      "Freezing layer 'model.6.sc.bn.bias'\n",
      "Freezing layer 'model.6.ec.conv.weight'\n",
      "Freezing layer 'model.6.ec.bn.weight'\n",
      "Freezing layer 'model.6.ec.bn.bias'\n",
      "Freezing layer 'model.7.m.0.conv1.conv.weight'\n",
      "Freezing layer 'model.7.m.0.conv1.bn.weight'\n",
      "Freezing layer 'model.7.m.0.conv1.bn.bias'\n",
      "Freezing layer 'model.7.m.0.conv2.conv.weight'\n",
      "Freezing layer 'model.7.m.0.conv2.bn.weight'\n",
      "Freezing layer 'model.7.m.0.conv2.bn.bias'\n",
      "Freezing layer 'model.7.m.1.conv1.conv.weight'\n",
      "Freezing layer 'model.7.m.1.conv1.bn.weight'\n",
      "Freezing layer 'model.7.m.1.conv1.bn.bias'\n",
      "Freezing layer 'model.7.m.1.conv2.conv.weight'\n",
      "Freezing layer 'model.7.m.1.conv2.bn.weight'\n",
      "Freezing layer 'model.7.m.1.conv2.bn.bias'\n",
      "Freezing layer 'model.7.m.2.conv1.conv.weight'\n",
      "Freezing layer 'model.7.m.2.conv1.bn.weight'\n",
      "Freezing layer 'model.7.m.2.conv1.bn.bias'\n",
      "Freezing layer 'model.7.m.2.conv2.conv.weight'\n",
      "Freezing layer 'model.7.m.2.conv2.bn.weight'\n",
      "Freezing layer 'model.7.m.2.conv2.bn.bias'\n",
      "Freezing layer 'model.7.m.3.conv1.conv.weight'\n",
      "Freezing layer 'model.7.m.3.conv1.bn.weight'\n",
      "Freezing layer 'model.7.m.3.conv1.bn.bias'\n",
      "Freezing layer 'model.7.m.3.conv2.conv.weight'\n",
      "Freezing layer 'model.7.m.3.conv2.bn.weight'\n",
      "Freezing layer 'model.7.m.3.conv2.bn.bias'\n",
      "Freezing layer 'model.7.m.4.conv1.conv.weight'\n",
      "Freezing layer 'model.7.m.4.conv1.bn.weight'\n",
      "Freezing layer 'model.7.m.4.conv1.bn.bias'\n",
      "Freezing layer 'model.7.m.4.conv2.conv.weight'\n",
      "Freezing layer 'model.7.m.4.conv2.bn.weight'\n",
      "Freezing layer 'model.7.m.4.conv2.bn.bias'\n",
      "Freezing layer 'model.7.m.5.conv1.conv.weight'\n",
      "Freezing layer 'model.7.m.5.conv1.bn.weight'\n",
      "Freezing layer 'model.7.m.5.conv1.bn.bias'\n",
      "Freezing layer 'model.7.m.5.conv2.conv.weight'\n",
      "Freezing layer 'model.7.m.5.conv2.bn.weight'\n",
      "Freezing layer 'model.7.m.5.conv2.bn.bias'\n",
      "Freezing layer 'model.7.sc.conv.weight'\n",
      "Freezing layer 'model.7.sc.bn.weight'\n",
      "Freezing layer 'model.7.sc.bn.bias'\n",
      "Freezing layer 'model.7.ec.conv.weight'\n",
      "Freezing layer 'model.7.ec.bn.weight'\n",
      "Freezing layer 'model.7.ec.bn.bias'\n",
      "Freezing layer 'model.8.conv.weight'\n",
      "Freezing layer 'model.8.bn.weight'\n",
      "Freezing layer 'model.8.bn.bias'\n",
      "Freezing layer 'model.9.m.0.conv1.conv.weight'\n",
      "Freezing layer 'model.9.m.0.conv1.bn.weight'\n",
      "Freezing layer 'model.9.m.0.conv1.bn.bias'\n",
      "Freezing layer 'model.9.m.0.conv2.conv.weight'\n",
      "Freezing layer 'model.9.m.0.conv2.bn.weight'\n",
      "Freezing layer 'model.9.m.0.conv2.bn.bias'\n",
      "Freezing layer 'model.9.m.1.conv1.conv.weight'\n",
      "Freezing layer 'model.9.m.1.conv1.bn.weight'\n",
      "Freezing layer 'model.9.m.1.conv1.bn.bias'\n",
      "Freezing layer 'model.9.m.1.conv2.conv.weight'\n",
      "Freezing layer 'model.9.m.1.conv2.bn.weight'\n",
      "Freezing layer 'model.9.m.1.conv2.bn.bias'\n",
      "Freezing layer 'model.9.m.2.conv1.conv.weight'\n",
      "Freezing layer 'model.9.m.2.conv1.bn.weight'\n",
      "Freezing layer 'model.9.m.2.conv1.bn.bias'\n",
      "Freezing layer 'model.9.m.2.conv2.conv.weight'\n",
      "Freezing layer 'model.9.m.2.conv2.bn.weight'\n",
      "Freezing layer 'model.9.m.2.conv2.bn.bias'\n",
      "Freezing layer 'model.9.m.3.conv1.conv.weight'\n",
      "Freezing layer 'model.9.m.3.conv1.bn.weight'\n",
      "Freezing layer 'model.9.m.3.conv1.bn.bias'\n",
      "Freezing layer 'model.9.m.3.conv2.conv.weight'\n",
      "Freezing layer 'model.9.m.3.conv2.bn.weight'\n",
      "Freezing layer 'model.9.m.3.conv2.bn.bias'\n",
      "Freezing layer 'model.9.m.4.conv1.conv.weight'\n",
      "Freezing layer 'model.9.m.4.conv1.bn.weight'\n",
      "Freezing layer 'model.9.m.4.conv1.bn.bias'\n",
      "Freezing layer 'model.9.m.4.conv2.conv.weight'\n",
      "Freezing layer 'model.9.m.4.conv2.bn.weight'\n",
      "Freezing layer 'model.9.m.4.conv2.bn.bias'\n",
      "Freezing layer 'model.9.m.5.conv1.conv.weight'\n",
      "Freezing layer 'model.9.m.5.conv1.bn.weight'\n",
      "Freezing layer 'model.9.m.5.conv1.bn.bias'\n",
      "Freezing layer 'model.9.m.5.conv2.conv.weight'\n",
      "Freezing layer 'model.9.m.5.conv2.bn.weight'\n",
      "Freezing layer 'model.9.m.5.conv2.bn.bias'\n",
      "Freezing layer 'model.9.sc.conv.weight'\n",
      "Freezing layer 'model.9.sc.bn.weight'\n",
      "Freezing layer 'model.9.sc.bn.bias'\n",
      "Freezing layer 'model.9.ec.conv.weight'\n",
      "Freezing layer 'model.9.ec.bn.weight'\n",
      "Freezing layer 'model.9.ec.bn.bias'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 75.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2304.8±1132.4 MB/s, size: 261.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/TACO_with_hard_negatives/train/labels... 3601 images, 911 backgrounds, 0 corrupt: 100%|██████████| 3601/3601 [00:02<00:00, 1523.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/TACO_with_hard_negatives/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 0.31G reserved, 0.30G allocated, 15.27G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    32857451       108.1         1.734         98.64           nan        (1, 3, 640, 640)                    list\n",
      "    32857451       216.2         3.070         93.64           nan        (2, 3, 640, 640)                    list\n",
      "    32857451       432.4         4.798         125.6           nan        (4, 3, 640, 640)                    list\n",
      "    32857451       864.8         8.091         191.3           nan        (8, 3, 640, 640)                    list\n",
      "    32857451        1730        14.619         328.6           nan       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 9 for CUDA:0 9.44G/15.89G (59%) ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2199.9±1455.2 MB/s, size: 139.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/TACO_with_hard_negatives/train/labels.cache... 3601 images, 911 backgrounds, 0 corrupt: 100%|██████████| 3601/3601 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 483.2±278.0 MB/s, size: 53.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/TACO_with_hard_negatives/valid/labels... 456 images, 112 backgrounds, 0 corrupt: 100%|██████████| 456/456 [00:00<00:00, 1458.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/TACO_with_hard_negatives/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/v2_rtdetr/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.00984375), 226 bias(decay=0.0)\n",
      "Resuming training /kaggle/input/rtdetr/pytorch/default/1/rtdetr_last.pt from epoch 186 to 300 total epochs\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/v2_rtdetr\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    186/300      4.64G      1.745     0.5532      1.422         10        640: 100%|██████████| 401/401 [03:38<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:11<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.349      0.238      0.205     0.0747\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    187/300      6.08G     0.8141     0.9673      0.294          3        640: 100%|██████████| 401/401 [03:38<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.236      0.172      0.114     0.0357\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    188/300      6.15G     0.7836     0.8347     0.2659          3        640: 100%|██████████| 401/401 [03:38<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.257      0.254      0.176     0.0645\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    189/300      6.22G      0.818     0.6736     0.2694          2        640: 100%|██████████| 401/401 [03:38<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.276      0.302      0.223     0.0808\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    190/300      6.29G     0.7807     0.6476     0.2633          9        640: 100%|██████████| 401/401 [03:38<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.312       0.34      0.266      0.106\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    191/300      6.37G     0.7516     0.6264     0.2515          3        640: 100%|██████████| 401/401 [03:38<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.402      0.363      0.341      0.152\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    192/300      6.44G     0.7654      0.618     0.2593          6        640: 100%|██████████| 401/401 [03:38<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.504      0.411       0.41      0.192\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    193/300      6.47G     0.7601     0.6201     0.2576          9        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.574      0.464      0.471      0.235\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    194/300      6.58G     0.7612     0.6067     0.2459          1        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.644      0.481      0.499      0.259\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    195/300      6.65G     0.7652     0.6035     0.2563         22        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.693      0.513      0.548      0.294\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    196/300      6.72G     0.7598     0.6047     0.2558          1        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.725      0.542      0.571      0.317\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    197/300      6.79G     0.7482     0.6076      0.251          2        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.708      0.564      0.582      0.331\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    198/300      6.86G     0.7607     0.5931     0.2515         13        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.741       0.56      0.588       0.34\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    199/300      6.94G     0.7271     0.6029     0.2459          1        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.755      0.565      0.596      0.347\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    200/300      6.97G     0.7509     0.5926     0.2435          4        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325       0.76      0.567        0.6      0.349\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    201/300      7.08G     0.7395     0.5952     0.2513          7        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325       0.77      0.573      0.606      0.353\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    202/300      7.15G     0.7269     0.5967      0.245          7        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.764      0.581      0.614      0.356\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    203/300      7.22G     0.7363     0.5958       0.25          2        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.761      0.589      0.617       0.36\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    204/300      7.27G     0.7297      0.585     0.2329          0        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.773      0.588      0.618      0.361\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    205/300      7.36G     0.7415     0.5823     0.2405          9        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.765       0.59      0.618       0.36\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    206/300      7.44G     0.7327     0.5928     0.2442          2        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.767      0.587      0.616       0.36\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    207/300      7.47G     0.7354     0.5887     0.2427          3        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.777      0.589      0.619      0.364\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    208/300      7.56G     0.7156     0.6015     0.2413          0        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.782      0.592      0.621      0.363\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    209/300      7.65G     0.7426     0.5899      0.244          1        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.776      0.595      0.623      0.365\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    210/300      7.72G     0.7459     0.5879     0.2442          3        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.782      0.594      0.625      0.367\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    211/300      7.79G     0.7369     0.5832     0.2418          1        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.795      0.591      0.625      0.369\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    212/300      7.84G     0.7357     0.5782     0.2414          0        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.789      0.597      0.624      0.368\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    213/300      7.94G     0.7552     0.5981     0.2503         12        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.776      0.597      0.622      0.369\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    214/300      7.97G     0.7293     0.5864     0.2426          2        640: 100%|██████████| 401/401 [03:41<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.784      0.599      0.622      0.371\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    215/300      4.71G     0.7343     0.5792     0.2438          1        640: 100%|██████████| 401/401 [03:45<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.767      0.601      0.624      0.371\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    216/300      4.82G     0.7381     0.5817     0.2388          3        640: 100%|██████████| 401/401 [03:48<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.775      0.604      0.623      0.371\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    217/300      4.87G     0.7354     0.5777     0.2397          1        640: 100%|██████████| 401/401 [03:48<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.768      0.604      0.625      0.374\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    218/300      4.92G     0.7261     0.5748     0.2348          6        640: 100%|██████████| 401/401 [03:52<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.765      0.605      0.628      0.374\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    219/300      4.97G     0.7365     0.5844     0.2439          3        640: 100%|██████████| 401/401 [03:53<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.781      0.601      0.627      0.374\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    220/300      5.08G     0.7303     0.5831     0.2394          2        640: 100%|██████████| 401/401 [03:49<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.795      0.603       0.63      0.378\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    221/300      5.13G     0.7254     0.5815     0.2389          3        640: 100%|██████████| 401/401 [03:48<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.791      0.604      0.629      0.378\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    222/300      5.25G     0.7347      0.574     0.2324          3        640: 100%|██████████| 401/401 [03:48<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.791      0.607      0.633      0.379\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    223/300      5.38G     0.7402     0.5662     0.2362          3        640: 100%|██████████| 401/401 [03:47<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.791      0.608      0.632      0.379\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    224/300      5.55G     0.7377     0.5753     0.2371         16        640: 100%|██████████| 401/401 [03:51<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.793      0.605      0.634      0.382\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    225/300      5.67G     0.7226     0.5752     0.2405         37        640: 100%|██████████| 401/401 [03:51<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.797      0.604      0.634      0.382\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    226/300       5.8G     0.7047     0.5667     0.2371         13        640: 100%|██████████| 401/401 [03:49<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.798      0.602      0.634      0.382\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    227/300       5.9G     0.7041     0.5671     0.2321          0        640: 100%|██████████| 401/401 [03:48<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.795      0.605      0.634      0.381\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    228/300      6.05G     0.7282     0.5686     0.2431          0        640: 100%|██████████| 401/401 [03:50<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.795      0.604      0.635      0.382\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    229/300      6.23G     0.7371     0.5758     0.2386          2        640: 100%|██████████| 401/401 [03:49<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.798      0.603      0.636      0.383\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    230/300      6.35G     0.7283     0.5686     0.2439          3        640: 100%|██████████| 401/401 [03:49<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.792      0.608      0.635      0.383\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    231/300      6.47G     0.7372     0.5741     0.2431          2        640: 100%|██████████| 401/401 [03:49<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.801      0.609       0.64      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    232/300      6.63G     0.7294     0.5598     0.2401          0        640: 100%|██████████| 401/401 [03:50<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.801      0.608       0.64      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    233/300      6.78G     0.7136     0.5661     0.2364          2        640: 100%|██████████| 401/401 [03:49<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.801      0.605      0.639      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    234/300       6.9G     0.7295     0.5715     0.2368         15        640: 100%|██████████| 401/401 [03:51<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.802      0.607       0.64      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    235/300      6.98G     0.7451      0.561     0.2399         10        640: 100%|██████████| 401/401 [03:51<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.802      0.604      0.641      0.388\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    236/300      7.33G     0.7173     0.5709     0.2303          2        640: 100%|██████████| 401/401 [03:52<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.809      0.603      0.641      0.389\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    237/300       7.4G      0.716     0.5755     0.2366          7        640: 100%|██████████| 401/401 [03:47<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.814      0.606      0.643      0.389\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    238/300      7.47G     0.7283     0.5749     0.2408          9        640: 100%|██████████| 401/401 [03:46<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.806       0.61      0.642      0.389\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    239/300      7.58G     0.7045     0.5669     0.2292          0        640: 100%|██████████| 401/401 [03:48<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.809       0.61       0.64      0.388\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    240/300       7.7G     0.7316     0.5677     0.2301          0        640: 100%|██████████| 401/401 [03:47<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.804      0.608       0.64      0.388\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    241/300      7.85G     0.7095     0.5683     0.2368          2        640: 100%|██████████| 401/401 [03:41<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325        0.8      0.609      0.639      0.388\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    242/300      7.98G     0.7286      0.561     0.2309         10        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.801      0.607       0.64      0.389\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    243/300      4.84G     0.7276     0.5684     0.2381          7        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.797      0.609      0.639      0.389\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    244/300      4.84G     0.7227     0.5666     0.2285          2        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.799      0.606      0.639      0.389\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    245/300      4.89G     0.7233     0.5652     0.2378          6        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.806      0.608      0.639      0.389\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    246/300      4.89G     0.7258     0.5618     0.2272          7        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.804       0.61       0.64      0.389\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    247/300      4.99G     0.7177     0.5624     0.2306         13        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.804       0.61       0.64       0.39\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    248/300      5.05G     0.7206     0.5667     0.2321          0        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.801       0.61      0.641       0.39\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    249/300       5.1G     0.7297     0.5619     0.2351          1        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.803      0.611       0.64      0.389\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    250/300      5.23G     0.7423     0.5563     0.2335          3        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325        0.8      0.609      0.639      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    251/300      5.41G     0.7214     0.5536     0.2324          9        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.798      0.611      0.639      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    252/300      5.54G     0.7165     0.5653     0.2366          2        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.799      0.609      0.638      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    253/300      5.66G     0.7062     0.5631     0.2364          4        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.799      0.608      0.639      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    254/300      5.78G     0.7262     0.5565     0.2351          5        640: 100%|██████████| 401/401 [03:42<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.799      0.606      0.639      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    255/300      5.96G     0.7153     0.5621     0.2359          9        640: 100%|██████████| 401/401 [03:41<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.796      0.605      0.635      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    256/300      6.04G     0.7201     0.5631     0.2343          5        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.792      0.605      0.635      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    257/300       6.2G     0.7176     0.5639     0.2269          2        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.787      0.603      0.635      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    258/300      6.32G     0.6879     0.5579     0.2209          4        640: 100%|██████████| 401/401 [03:44<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325       0.79      0.607      0.635      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    259/300       6.5G     0.6989     0.5626     0.2343          1        640: 100%|██████████| 401/401 [03:43<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325        0.8      0.603      0.636      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    260/300      6.62G     0.7352     0.5591     0.2301          1        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.788      0.609      0.636      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    261/300      6.74G     0.7009     0.5555      0.222          3        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.795      0.606      0.635      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    262/300      6.92G     0.7124      0.553     0.2275          6        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.797      0.606      0.636      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    263/300      7.01G     0.7129     0.5535     0.2319          2        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.788      0.609      0.635      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    264/300      7.16G     0.7178     0.5568     0.2306         26        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.795      0.606      0.635      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    265/300      7.29G     0.7028     0.5659     0.2296          1        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.794      0.604      0.634      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    266/300      7.46G      0.709     0.5627     0.2347         18        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.804      0.601      0.634      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    267/300      7.59G     0.7214     0.5668     0.2385          2        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.794      0.606      0.635      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    268/300      7.71G     0.7078     0.5514     0.2265         15        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.789      0.608      0.635      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    269/300      7.84G      0.695     0.5569     0.2333          9        640: 100%|██████████| 401/401 [03:42<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.809        0.6      0.634      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    270/300      7.98G     0.7262     0.5564     0.2324          4        640: 100%|██████████| 401/401 [03:46<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.808      0.598      0.635      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    271/300      4.87G     0.7087     0.5554     0.2288         14        640: 100%|██████████| 401/401 [03:43<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.808        0.6      0.635      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    272/300      4.87G      0.703     0.5603     0.2315          8        640: 100%|██████████| 401/401 [03:42<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325       0.81      0.598      0.636      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    273/300      4.87G     0.7344     0.5509     0.2403          3        640: 100%|██████████| 401/401 [03:43<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.817      0.599      0.636      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    274/300      4.92G     0.7361     0.5433     0.2328          0        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.809        0.6      0.635      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    275/300      4.97G     0.7101     0.5476     0.2297          5        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.805      0.601      0.635      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    276/300      5.08G     0.7059     0.5524     0.2273          0        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.798      0.608      0.635      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    277/300      5.13G     0.6985     0.5575     0.2297          0        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.806      0.602      0.636      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    278/300      5.24G     0.6996      0.556     0.2308         11        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.806      0.602      0.636      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    279/300      5.42G      0.717     0.5481     0.2246          6        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.809        0.6      0.636      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    280/300      5.54G     0.7128     0.5537     0.2302          1        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.811      0.599      0.636      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    281/300      5.72G     0.7229     0.5498     0.2284          2        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.812      0.598      0.637      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    282/300      5.79G     0.7227     0.5489     0.2313          2        640: 100%|██████████| 401/401 [03:39<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.816      0.599      0.638      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    283/300      5.92G      0.722      0.548     0.2306         10        640: 100%|██████████| 401/401 [03:39<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.801      0.606      0.638      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    284/300      6.05G     0.7086      0.551     0.2307          3        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.806      0.606      0.638      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    285/300      6.22G     0.6966     0.5542     0.2315         11        640: 100%|██████████| 401/401 [03:40<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.792      0.608      0.636      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    286/300      6.32G     0.7164     0.5471      0.233          0        640: 100%|██████████| 401/401 [03:46<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325       0.81        0.6      0.637      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    287/300      6.47G     0.6965      0.555     0.2296         11        640: 100%|██████████| 401/401 [03:47<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.812        0.6      0.637      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    288/300      6.64G     0.7052     0.5439     0.2234          5        640: 100%|██████████| 401/401 [03:46<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.812        0.6      0.637      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    289/300      6.77G     0.7098     0.5579     0.2303          6        640: 100%|██████████| 401/401 [03:46<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.812      0.601      0.637      0.387\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    290/300      6.89G     0.7226     0.5496     0.2316         11        640: 100%|██████████| 401/401 [03:46<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.815        0.6      0.637      0.386\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    291/300      7.03G      0.529      0.469     0.1827          2        640: 100%|██████████| 401/401 [03:46<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.814      0.599      0.636      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    292/300      7.17G     0.5298     0.4717     0.1913          0        640: 100%|██████████| 401/401 [03:45<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.809        0.6      0.637      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    293/300      7.31G      0.524     0.4732     0.1881          3        640: 100%|██████████| 401/401 [03:45<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.811      0.598      0.637      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    294/300      7.43G     0.5301      0.468     0.1857          2        640: 100%|██████████| 401/401 [03:45<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.814      0.597      0.636      0.384\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    295/300      7.56G     0.5308      0.468     0.1872          1        640: 100%|██████████| 401/401 [03:45<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.814      0.597      0.635      0.384\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    296/300      7.71G     0.5186     0.4631     0.1855          0        640: 100%|██████████| 401/401 [03:45<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.816      0.596      0.636      0.384\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    297/300      7.86G     0.5118     0.4691     0.1851         11        640: 100%|██████████| 401/401 [03:45<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.818      0.598      0.638      0.386\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "    298/300      7.93G     0.5163      0.458     0.1899          0        640: 100%|██████████| 401/401 [03:45<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:10<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.815      0.598      0.639      0.386\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 50 epochs. Best results observed at epoch 248, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "113 epochs completed in 7.369 hours.\n",
      "Optimizer stripped from runs/detect/v2_rtdetr/weights/last.pt, 66.2MB\n",
      "Optimizer stripped from runs/detect/v2_rtdetr/weights/best.pt, 66.2MB\n",
      "\n",
      "Validating runs/detect/v2_rtdetr/weights/best.pt...\n",
      "Ultralytics 8.3.159 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
      "rt-detr-l summary: 302 layers, 32,035,115 parameters, 0 gradients, 103.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:12<00:00,  2.12it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        456       1325      0.798       0.61       0.64      0.389\n",
      "             Cigarette         37         97      0.593      0.346      0.374      0.164\n",
      "        Plastic bottle         53         93      0.848      0.677      0.716      0.464\n",
      "       Plastic wrapper         88        142      0.838      0.582       0.62      0.332\n",
      "     Plastic container         40         46      0.799      0.739      0.794      0.513\n",
      "           Plastic cup         22         25       0.73       0.52      0.535      0.396\n",
      "       Plastic lid/cap         55         67      0.863      0.755      0.776      0.497\n",
      "       Plastic utensil         20         22       0.79      0.864       0.87      0.506\n",
      "         Plastic straw         19         32      0.678      0.312      0.366      0.192\n",
      "           Plastic bag         43         54      0.878      0.833      0.856      0.553\n",
      "        Plastic gloves          8          8      0.991          1      0.995      0.641\n",
      "        Foam container         17         23      0.564      0.435       0.44       0.25\n",
      "           Paper straw         16         16      0.989      0.875      0.918      0.587\n",
      "                 Paper         27         33      0.884      0.464      0.497      0.296\n",
      "       Paper container         27         36      0.834      0.695       0.76      0.452\n",
      "                Carton         32         47      0.727      0.702      0.643       0.39\n",
      "         Metal can/lid         39         80      0.678        0.5      0.539      0.299\n",
      "           Scrap metal         11         28      0.753      0.714      0.754      0.329\n",
      "                 Glass         20        110      0.891      0.164      0.205      0.101\n",
      "        Aluminium/foil         26         46      0.897      0.674      0.821      0.457\n",
      "           Rope/string         17         17      0.864      0.706      0.767      0.513\n",
      "               Aerosol         23         23      0.947       0.87      0.867      0.623\n",
      "               Tissues         18         20      0.685        0.6      0.532      0.384\n",
      "      Unlabeled litter         53         89       0.66      0.382      0.424      0.188\n",
      "            Food waste         25        109      0.905      0.522      0.642      0.448\n",
      "                 Other         36         62      0.663      0.317      0.296      0.155\n",
      "Speed: 0.1ms preprocess, 19.4ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/v2_rtdetr\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7cfc9ebe9f50>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,  1.7136e-05,  8.5681e-06,           0],\n",
       "       [          1,           1,           1, ...,  0.00011313,  5.6564e-05,           0],\n",
       "       [          1,           1,           1, ...,  3.8928e-05,  1.9464e-05,           0],\n",
       "       ...,\n",
       "       [          1,           1,           1, ...,  1.3785e-05,  6.8926e-06,           0],\n",
       "       [          1,           1,           1, ...,  0.00014248,  7.1241e-05,           0],\n",
       "       [          1,           1,           1, ...,   1.901e-05,  9.5049e-06,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0057984,   0.0057984,   0.0058007, ...,           0,           0,           0],\n",
       "       [   0.022759,    0.022759,    0.022761, ...,           0,           0,           0],\n",
       "       [  0.0092549,   0.0092549,   0.0092575, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [  0.0060024,   0.0060024,   0.0060096, ...,           0,           0,           0],\n",
       "       [   0.015534,    0.015534,    0.015552, ...,           0,           0,           0],\n",
       "       [       0.01,        0.01,    0.010001, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.002912,    0.002912,   0.0029131, ...,           1,           1,           1],\n",
       "       [   0.011544,    0.011544,    0.011546, ...,           1,           1,           1],\n",
       "       [  0.0046558,   0.0046558,   0.0046571, ...,           1,           1,           1],\n",
       "       ...,\n",
       "       [  0.0030173,   0.0030173,   0.0030209, ...,           1,           1,           1],\n",
       "       [  0.0078352,   0.0078352,   0.0078447, ...,           1,           1,           1],\n",
       "       [   0.005054,    0.005054,   0.0050545, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.65979,     0.65979,     0.65979, ...,           0,           0,           0],\n",
       "       [     0.7957,      0.7957,      0.7957, ...,           0,           0,           0],\n",
       "       [    0.76056,     0.76056,     0.76056, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [     0.5618,      0.5618,      0.5618, ...,           0,           0,           0],\n",
       "       [    0.88991,     0.88991,     0.88991, ...,           0,           0,           0],\n",
       "       [    0.46774,     0.46774,     0.46774, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.4142155052412664\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.16414,     0.46354,     0.33209,     0.51278,     0.39623,     0.49651,     0.50636,      0.1916,     0.55321,     0.64053,     0.24977,     0.58668,     0.29581,     0.45208,     0.38994,     0.29945,     0.32884,     0.10073,     0.45688,     0.51278,     0.62257,     0.38435,     0.18755,      0.4483,\n",
       "           0.15477])\n",
       "names: {0: 'Cigarette', 1: 'Plastic bottle', 2: 'Plastic wrapper', 3: 'Plastic container', 4: 'Plastic cup', 5: 'Plastic lid/cap', 6: 'Plastic utensil', 7: 'Plastic straw', 8: 'Plastic bag', 9: 'Plastic gloves', 10: 'Foam container', 11: 'Paper straw', 12: 'Paper', 13: 'Paper container', 14: 'Carton', 15: 'Metal can/lid', 16: 'Scrap metal', 17: 'Glass', 18: 'Aluminium/foil', 19: 'Rope/string', 20: 'Aerosol', 21: 'Tissues', 22: 'Unlabeled litter', 23: 'Food waste', 24: 'Other'}\n",
       "nt_per_class: array([ 97,  93, 142,  46,  25,  67,  22,  32,  54,   8,  23,  16,  33,  36,  47,  80,  28, 110,  46,  17,  23,  20,  89, 109,  62])\n",
       "nt_per_image: array([37, 53, 88, 40, 22, 55, 20, 19, 43,  8, 17, 16, 27, 27, 32, 39, 11, 20, 26, 17, 23, 18, 53, 25, 36])\n",
       "results_dict: {'metrics/precision(B)': 0.7979036615936225, 'metrics/recall(B)': 0.6099469598579905, 'metrics/mAP50(B)': 0.6402581294603551, 'metrics/mAP50-95(B)': 0.38909965810581204, 'fitness': 0.4142155052412664}\n",
       "save_dir: PosixPath('runs/detect/v2_rtdetr')\n",
       "speed: {'preprocess': 0.1469947938746548, 'inference': 19.417791947353976, 'loss': 0.000551054821890399, 'postprocess': 0.4473206710444126}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import RTDETR\n",
    "\n",
    "model = RTDETR('/kaggle/input/rtdetr/pytorch/default/1/rtdetr_last.pt')  \n",
    "\n",
    "model.train(\n",
    "    data='/kaggle/working/TACO_with_hard_negatives/data.yaml',\n",
    "    name='v2_rtdetr_continued',\n",
    "    resume=True,\n",
    "    epochs=300,\n",
    "    batch=-1,\n",
    "    device=0,\n",
    "    imgsz=640,\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.01,\n",
    "    warmup_epochs=3.0,\n",
    "    warmup_momentum=0.8,\n",
    "    warmup_bias_lr=0.1,\n",
    "    cos_lr=True,\n",
    "    amp=True,\n",
    "    val=True,\n",
    "    patience=50,\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    "    save=True,\n",
    "    plots=True,\n",
    "    overlap_mask=True,\n",
    "    mask_ratio=4,\n",
    "    freeze=10,\n",
    "    dropout=0.2,\n",
    "\n",
    "    #  Spatial augmentations\n",
    "    degrees=20.0,\n",
    "    translate=0.1,\n",
    "    scale=0.8,\n",
    "    shear=10.0,\n",
    "    perspective=0.0005,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.2,\n",
    "    cutmix=0.2,\n",
    "    copy_paste=0.3,\n",
    "\n",
    "\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7729157,
     "sourceId": 12265418,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 384992,
     "modelInstanceId": 364107,
     "sourceId": 448506,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26711.618222,
   "end_time": "2025-06-25T11:41:59.480576",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-25T04:16:47.862354",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
